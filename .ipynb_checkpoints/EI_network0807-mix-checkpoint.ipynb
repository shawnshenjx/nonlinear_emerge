{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[ 1.4213, -0.9358,  2.0860,  0.4001, -0.2723, -0.1044]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -1.4873,  0.9007, -2.1055, -0.6784,  1.2345],\n",
      "        [-0.0431,  0.0000, -0.7521,  1.6487,  0.3925,  1.4036],\n",
      "        [-0.7279,  0.5594,  0.0000,  0.7624, -1.6423,  0.1596],\n",
      "        [-0.4974, -0.4396,  0.3189,  0.0000, -0.3057,  0.7746],\n",
      "        [ 0.0349, -0.3211,  1.5736, -0.8455,  0.0000, -2.1228],\n",
      "        [-1.2347,  0.4879, -1.4181,  0.8963, -0.0499,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "1\n",
      "tensor([[-0.4597, -0.2016,  0.3710, -1.2810,  1.3066,  0.2153]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -1.3873,  0.8007,  2.0055,  0.7784, -1.3345],\n",
      "        [-0.0569,  0.0000, -0.6521, -1.5487, -0.4925, -1.3036],\n",
      "        [ 0.8279,  0.6594,  0.0000, -0.6624,  1.7423, -0.2596],\n",
      "        [ 0.3974, -0.5396,  0.4189,  0.0000,  0.2057, -0.6746],\n",
      "        [ 0.0651, -0.2211,  1.4736,  0.7455,  0.0000,  2.0228],\n",
      "        [ 1.1347,  0.3879, -1.3181, -0.7963, -0.0501,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "2\n",
      "tensor([[ 0.4545, -1.2711,  1.0150, -0.1632,  0.3544, -1.1337]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -1.2995,  0.7013,  1.9122,  0.8239,  1.3465],\n",
      "        [ 0.1070,  0.0000, -0.5723, -1.4700, -0.5547,  1.2405],\n",
      "        [-0.7670,  0.7587,  0.0000, -0.7320,  1.7548,  0.2851],\n",
      "        [-0.2986, -0.5870,  0.4051,  0.0000,  0.1252,  0.5927],\n",
      "        [-0.0051, -0.1210,  1.3937,  0.6460,  0.0000, -1.9917],\n",
      "        [-1.0400,  0.3637, -1.3057, -0.7958, -0.1337,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "3\n",
      "tensor([[-1.6736, -0.1457, -2.2090,  2.3834,  0.3703,  0.7969]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -1.3286, -0.6343, -1.8570,  0.8924, -1.3069],\n",
      "        [-0.1714,  0.0000,  0.4946,  1.3955, -0.5634, -1.1905],\n",
      "        [ 0.7633,  0.8536,  0.0000,  0.8038,  1.6968, -0.3274],\n",
      "        [ 0.3402, -0.5402, -0.3477,  0.0000,  0.0446, -0.6210],\n",
      "        [ 0.0371, -0.0293, -1.3108, -0.5473,  0.0000,  1.9235],\n",
      "        [ 0.9622,  0.2975,  1.2412,  0.7486, -0.0799,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "4\n",
      "tensor([[-0.7704,  0.4942,  0.5294, -1.4666,  2.0114, -0.2957]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  1.3494,  0.5775,  1.7860,  0.9450,  1.2711],\n",
      "        [-0.1535,  0.0000, -0.4295, -1.3179, -0.5653,  1.1501],\n",
      "        [ 0.7785, -0.9059,  0.0000, -0.8811,  1.6516,  0.3564],\n",
      "        [ 0.3742,  0.5027,  0.3043,  0.0000, -0.0213,  0.6478],\n",
      "        [ 0.0571, -0.0510,  1.2446,  0.4716,  0.0000, -1.8644],\n",
      "        [ 0.8939, -0.2467, -1.1887, -0.7606, -0.0371,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "5\n",
      "tensor([[ 0.2943,  0.6677, -1.3193, -2.0292, -0.7955,  1.6126]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  1.3048, -0.6182,  1.7086, -1.0112, -1.2087],\n",
      "        [ 0.1286,  0.0000,  0.3662, -1.2986,  0.5144, -1.0870],\n",
      "        [-0.7855, -0.8610,  0.0000, -0.9034, -1.5850, -0.4155],\n",
      "        [-0.4043,  0.4590, -0.2988,  0.0000,  0.0678, -0.6592],\n",
      "        [-0.0684, -0.0165, -1.1792,  0.4631,  0.0000,  1.7969],\n",
      "        [-0.8389, -0.2678,  1.1250, -0.8020, -0.0271,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "6\n",
      "tensor([[-0.2419, -0.5134,  0.0246,  0.6978, -0.5291,  0.8412]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -1.2638,  0.6525, -1.6355, -1.0704, -1.1405],\n",
      "        [-0.1316,  0.0000, -0.3125,  1.2784,  0.4673, -1.0343],\n",
      "        [ 0.7791,  0.8193,  0.0000,  0.9197, -1.5292, -0.4720],\n",
      "        [ 0.4259, -0.4170,  0.2928,  0.0000,  0.1079, -0.6391],\n",
      "        [ 0.0560, -0.0172,  1.1224, -0.4720,  0.0000,  1.7237],\n",
      "        [ 0.7905,  0.2836, -1.0697,  0.8280, -0.0829,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "7\n",
      "tensor([[-0.1561, -0.3301, -0.6801,  0.0675,  0.6606,  0.2566]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -1.2250, -0.6879, -1.5581,  1.1206, -1.0888],\n",
      "        [-0.1426,  0.0000,  0.2692,  1.2453, -0.4251, -0.9826],\n",
      "        [ 0.7690,  0.7833,  0.0000,  0.9302,  1.4812, -0.5183],\n",
      "        [ 0.4440, -0.3822, -0.2879,  0.0000, -0.1436, -0.6185],\n",
      "        [ 0.0427, -0.0472, -1.0701, -0.4881,  0.0000,  1.6619],\n",
      "        [ 0.7482,  0.2978,  1.0218,  0.8523,  0.1319,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "8\n",
      "tensor([[-0.6331,  0.5356,  1.3829, -0.2605, -0.1473,  0.9805]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  1.1882,  0.7205,  1.4877, -1.1600, -1.0463],\n",
      "        [-0.1340,  0.0000, -0.2329, -1.2161,  0.3846, -0.9378],\n",
      "        [ 0.7596, -0.7534,  0.0000, -0.9438, -1.4360, -0.5648],\n",
      "        [ 0.4628,  0.3564,  0.2824,  0.0000,  0.1713, -0.5937],\n",
      "        [ 0.0255,  0.0697,  1.0249,  0.4941,  0.0000,  1.6001],\n",
      "        [ 0.7114, -0.3107, -0.9796, -0.8752, -0.1747,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "9\n",
      "tensor([[ 0.1243, -0.0371,  1.5006, -1.7651, -0.6222,  0.4326]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -1.1558,  0.7488,  1.4214, -1.1946, -1.0047],\n",
      "        [ 0.1341,  0.0000, -0.2007, -1.1942,  0.3501, -0.8940],\n",
      "        [-0.7509,  0.7271,  0.0000, -0.9560, -1.3958, -0.6058],\n",
      "        [-0.4728, -0.3352,  0.2740,  0.0000,  0.1960, -0.5689],\n",
      "        [-0.0085, -0.0899,  0.9845,  0.4976,  0.0000,  1.5428],\n",
      "        [-0.6775,  0.3221, -0.9425, -0.8968, -0.2127,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "10\n",
      "tensor([[ 0.4863, -0.1824, -0.1807,  0.8405,  0.0494, -0.0625]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -1.1273, -0.7742, -1.3635,  1.2251,  0.9667],\n",
      "        [ 0.1565,  0.0000,  0.1731,  1.1799, -0.3184,  0.8554],\n",
      "        [-0.7360,  0.7041,  0.0000,  0.9757,  1.3604,  0.6387],\n",
      "        [-0.4945, -0.3179, -0.2607,  0.0000, -0.2186,  0.5400],\n",
      "        [ 0.0041, -0.1082, -0.9486, -0.5032,  0.0000, -1.4914],\n",
      "        [-0.6473,  0.3322,  0.9070,  0.9077,  0.2463,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "11\n",
      "tensor([[-1.6900, -0.3149,  0.7170,  1.2702,  1.4905, -0.8611]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -1.0782,  0.7832, -1.3055,  1.2265,  0.9720],\n",
      "        [-0.2081,  0.0000, -0.1356,  1.1303, -0.2691,  0.7966],\n",
      "        [ 0.6884,  0.6653,  0.0000,  0.9324,  1.3419,  0.6398],\n",
      "        [ 0.4564, -0.3519,  0.2937,  0.0000, -0.2039,  0.4855],\n",
      "        [ 0.0205, -0.1107,  0.9114, -0.4584,  0.0000, -1.4324],\n",
      "        [ 0.5978,  0.3288, -0.8696,  0.8658,  0.2837,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "tensor([[-0.4979, -0.5807, -0.6008,  0.9443,  0.0971,  0.9758]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -1.0320, -0.7831, -1.2531,  1.2236, -0.9792],\n",
      "        [-0.2584,  0.0000,  0.1074,  1.0838, -0.2282, -0.7457],\n",
      "        [ 0.6362,  0.6330,  0.0000,  0.8909,  1.3198, -0.6466],\n",
      "        [ 0.4261, -0.3842, -0.3258,  0.0000, -0.1877, -0.4356],\n",
      "        [ 0.0334, -0.1109, -0.8703, -0.4180,  0.0000,  1.3761],\n",
      "        [ 0.5483,  0.3269,  0.8385,  0.8284,  0.3154,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "13\n",
      "tensor([[-1.2330,  0.0659, -0.3729,  0.8045, -0.6008,  0.8123]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  0.9913, -0.7830, -1.2060, -1.2151, -0.9851],\n",
      "        [-0.3084,  0.0000,  0.0787,  1.0423,  0.2006, -0.7044],\n",
      "        [ 0.5870, -0.6045,  0.0000,  0.8540, -1.2976, -0.6533],\n",
      "        [ 0.3975,  0.4123, -0.3572,  0.0000,  0.1758, -0.3923],\n",
      "        [ 0.0420,  0.1107, -0.8343, -0.3809,  0.0000,  1.3242],\n",
      "        [ 0.5007, -0.3266,  0.8087,  0.7946, -0.3402,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "14\n",
      "tensor([[ 0.0648, -0.7833,  0.7091,  0.1402, -0.3678, -0.0869]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.9505,  0.7864, -1.1653, -1.2022,  0.9779],\n",
      "        [ 0.3524,  0.0000, -0.0539,  1.0045,  0.1745,  0.6678],\n",
      "        [-0.5384,  0.5791,  0.0000,  0.8201, -1.2747,  0.6551],\n",
      "        [-0.3709, -0.4357,  0.3845,  0.0000,  0.1653,  0.3468],\n",
      "        [-0.0688, -0.1154,  0.7944, -0.3424,  0.0000, -1.2628],\n",
      "        [-0.4683,  0.3233, -0.7861,  0.7679, -0.3673,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "15\n",
      "tensor([[ 2.4516,  0.4643, -0.5304, -0.5097,  1.1977, -0.6108]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.9137, -0.7898,  1.1275,  1.1906,  0.9720],\n",
      "        [ 0.3891,  0.0000,  0.0315, -0.9704, -0.1507,  0.6349],\n",
      "        [-0.4888, -0.5562,  0.0000, -0.7880,  1.2541,  0.6559],\n",
      "        [-0.3459,  0.4570, -0.4106,  0.0000, -0.1563,  0.3052],\n",
      "        [-0.0972,  0.1197, -0.7592,  0.3061,  0.0000, -1.2068],\n",
      "        [-0.4314, -0.3205,  0.7667, -0.7414,  0.3919,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "16\n",
      "tensor([[ 0.6688,  1.4223, -0.4666, -0.5858, -0.1227,  0.4090]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  0.8641, -0.7911,  1.0922, -1.1778, -0.9701],\n",
      "        [ 0.4160,  0.0000,  0.0128, -0.9407,  0.1298, -0.6075],\n",
      "        [-0.4338, -0.5194,  0.0000, -0.7565, -1.2368, -0.6512],\n",
      "        [-0.3284,  0.4680, -0.4301,  0.0000,  0.1501, -0.2711],\n",
      "        [-0.1237,  0.1290, -0.7279,  0.2747,  0.0000,  1.1568],\n",
      "        [-0.3920, -0.3125,  0.7480, -0.7160, -0.4151,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "17\n",
      "tensor([[ 1.1595, -1.3886, -0.4112,  0.2052,  0.0473, -0.3762]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.8177, -0.7920, -1.0603,  1.1659,  0.9648],\n",
      "        [ 0.4313,  0.0000, -0.0053,  0.9149, -0.1146,  0.5676],\n",
      "        [-0.3783,  0.4842,  0.0000,  0.7286,  1.2216,  0.6413],\n",
      "        [-0.3100, -0.4800, -0.4440,  0.0000, -0.1410,  0.2491],\n",
      "        [-0.1489, -0.1371, -0.6995, -0.2465,  0.0000, -1.1091],\n",
      "        [-0.3569,  0.3052,  0.7309,  0.6919,  0.4360,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "18\n",
      "tensor([[-1.6196, -2.1962,  1.5744,  2.1017, -0.5636,  1.2172]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.7639,  0.7844, -1.0043, -1.1444, -0.9777],\n",
      "        [-0.4706,  0.0000,  0.0302,  0.8643,  0.0897, -0.5158],\n",
      "        [ 0.3146,  0.4475,  0.0000,  0.6838, -1.2110, -0.6247],\n",
      "        [ 0.2771, -0.5005,  0.4683,  0.0000,  0.1250, -0.2178],\n",
      "        [ 0.1985, -0.1330,  0.6679, -0.1923,  0.0000,  1.0524],\n",
      "        [ 0.3146,  0.2954, -0.7135,  0.6513, -0.4569,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "19\n",
      "tensor([[ 1.3761,  1.4138, -0.4656, -0.8042, -1.5689,  0.9392]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000,  0.7145, -0.7799,  0.9523, -1.1244, -0.9908],\n",
      "        [ 0.5127,  0.0000, -0.0391, -0.8138,  0.0654, -0.4607],\n",
      "        [-0.2535, -0.4138,  0.0000, -0.6414, -1.2016, -0.6042],\n",
      "        [-0.2463,  0.5202, -0.4818,  0.0000,  0.1099, -0.1874],\n",
      "        [-0.2416,  0.1290, -0.6365,  0.1428,  0.0000,  1.0034],\n",
      "        [-0.2806, -0.2865,  0.6918, -0.6158, -0.4758,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "20\n",
      "tensor([[-0.3818,  3.2104,  0.0812, -0.6052, -1.5458,  0.3592]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000,  0.6602,  0.7757,  0.9050, -1.1059, -1.0025],\n",
      "        [-0.5474,  0.0000,  0.0466, -0.7687,  0.0431, -0.4096],\n",
      "        [ 0.1901, -0.3752,  0.0000, -0.6008, -1.1935, -0.5890],\n",
      "        [ 0.2200,  0.5350,  0.4933,  0.0000,  0.0964, -0.1585],\n",
      "        [ 0.2843,  0.1270,  0.6077,  0.0969,  0.0000,  0.9603],\n",
      "        [ 0.2484, -0.2725, -0.6718, -0.5825, -0.4929,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "21\n",
      "tensor([[-0.1211,  0.0705, -0.0534,  0.0973,  0.0654, -0.1901]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.6108, -0.7713, -0.8620,  1.0892,  1.0131],\n",
      "        [-0.5805,  0.0000, -0.0495,  0.7287, -0.0222,  0.3613],\n",
      "        [ 0.1317, -0.3411,  0.0000,  0.5641,  1.1863,  0.5746],\n",
      "        [ 0.1980,  0.5496, -0.5099,  0.0000, -0.0850,  0.1336],\n",
      "        [ 0.3218,  0.1255, -0.5801, -0.0544,  0.0000, -0.9217],\n",
      "        [ 0.2174, -0.2598,  0.6548,  0.5537,  0.5088,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "22\n",
      "tensor([[ 1.2088, -0.9129,  0.1116,  0.1558, -0.1051, -2.0558]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.5626,  0.7677, -0.8262, -1.0734,  1.0221],\n",
      "        [ 0.6108,  0.0000,  0.0525,  0.6909,  0.0038,  0.3169],\n",
      "        [-0.0795,  0.3105,  0.0000,  0.5278, -1.1796,  0.5607],\n",
      "        [-0.1795, -0.5589,  0.5271,  0.0000,  0.0748,  0.1092],\n",
      "        [-0.3580, -0.1193,  0.5559, -0.0321,  0.0000, -0.8887],\n",
      "        [-0.1891,  0.2492, -0.6391,  0.5203, -0.5229,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "23\n",
      "tensor([[ 0.0458, -2.1041,  0.4777, -0.0486,  0.7056, -2.0956]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.5217,  0.7518,  0.7938,  1.0618,  1.0364],\n",
      "        [ 0.6388,  0.0000,  0.0537, -0.6561,  0.0129,  0.2762],\n",
      "        [-0.0355,  0.2825,  0.0000, -0.4931,  1.1740,  0.5490],\n",
      "        [-0.1543, -0.5652,  0.5432,  0.0000, -0.0661,  0.0841],\n",
      "        [-0.3831, -0.1131,  0.5375,  0.0130,  0.0000, -0.8592],\n",
      "        [-0.1624,  0.2399, -0.6246, -0.4911,  0.5351,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "tensor([[-1.8263, -0.6176, -0.3264,  0.0105,  1.1772,  0.3686]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.4841, -0.7375, -0.7651,  1.0515, -1.0478],\n",
      "        [-0.6644,  0.0000, -0.0542,  0.6242,  0.0279, -0.2387],\n",
      "        [-0.0031,  0.2567,  0.0000,  0.4619,  1.1676, -0.5387],\n",
      "        [ 0.1321, -0.5711, -0.5572,  0.0000, -0.0584, -0.0618],\n",
      "        [ 0.4062, -0.1074, -0.5198,  0.0042,  0.0000,  0.8325],\n",
      "        [ 0.1373,  0.2316,  0.6117,  0.4641,  0.5467,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "25\n",
      "tensor([[-0.7587,  1.7421, -0.1354,  0.2081, -2.2093,  0.9121]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.4496, -0.7243, -0.7391, -1.0389, -1.0663],\n",
      "        [-0.6880,  0.0000, -0.0545,  0.5951, -0.0430, -0.2018],\n",
      "        [-0.0384, -0.2331,  0.0000,  0.4332, -1.1626, -0.5263],\n",
      "        [ 0.1126,  0.5764, -0.5697,  0.0000,  0.0528, -0.0470],\n",
      "        [ 0.4276,  0.1022, -0.5035,  0.0200,  0.0000,  0.8069],\n",
      "        [ 0.1160, -0.2241,  0.5999,  0.4394, -0.5562,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "26\n",
      "tensor([[ 0.0785, -0.1477, -0.1031, -0.3910,  0.7783,  1.6040]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.4107, -0.7122,  0.7162,  1.0275, -1.0817],\n",
      "        [ 0.7104,  0.0000, -0.0544, -0.5666,  0.0571, -0.1686],\n",
      "        [ 0.0701,  0.2062,  0.0000, -0.4084,  1.1578, -0.5141],\n",
      "        [-0.0946, -0.5759, -0.5806,  0.0000, -0.0474, -0.0341],\n",
      "        [-0.4473, -0.0985, -0.4888, -0.0348,  0.0000,  0.7830],\n",
      "        [-0.0964,  0.2162,  0.5892, -0.4167,  0.5649,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "27\n",
      "tensor([[ 0.9906, -0.6420,  1.1706,  1.6862, -0.0975, -0.3412]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.3754,  0.7012, -0.6952, -1.0172,  1.0946],\n",
      "        [ 0.7298,  0.0000,  0.0542,  0.5404, -0.0713,  0.1374],\n",
      "        [ 0.0937,  0.1799,  0.0000,  0.3851, -1.1547,  0.5009],\n",
      "        [-0.0789, -0.5743,  0.5908,  0.0000,  0.0438,  0.0230],\n",
      "        [-0.4623, -0.0941,  0.4754,  0.0487,  0.0000, -0.7595],\n",
      "        [-0.0704,  0.2102, -0.5796,  0.3966, -0.5720,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "28\n",
      "tensor([[ 0.7159,  1.4600, -0.2090, -0.0692,  1.1203, -0.2946]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.3441, -0.6881,  0.6775,  1.0095,  1.1085],\n",
      "        [ 0.7468,  0.0000, -0.0494, -0.5146,  0.0851,  0.1102],\n",
      "        [ 0.1150, -0.1548,  0.0000, -0.3569,  1.1538,  0.4920],\n",
      "        [-0.0646,  0.5739, -0.5853,  0.0000, -0.0386,  0.0151],\n",
      "        [-0.4766,  0.0896, -0.4648, -0.0638,  0.0000, -0.7390],\n",
      "        [-0.0470, -0.2039,  0.5749, -0.3726,  0.5797,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "29\n",
      "tensor([[ 2.1174, -0.7506, -0.2999,  0.7602,  0.0365, -0.0274]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.3135, -0.6778, -0.6614,  0.9942,  1.1195],\n",
      "        [ 0.7593,  0.0000, -0.0471,  0.4907,  0.0917,  0.0832],\n",
      "        [ 0.1319,  0.1316,  0.0000,  0.3308,  1.1450,  0.4824],\n",
      "        [-0.0520, -0.5723, -0.5805,  0.0000, -0.0346,  0.0078],\n",
      "        [-0.4976, -0.0831, -0.4587,  0.0765,  0.0000, -0.7248],\n",
      "        [-0.0282,  0.1988,  0.5694,  0.3502,  0.5837,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "30\n",
      "tensor([[ 1.4479, -0.1466,  1.9875, -0.8349, -1.1347,  0.1326]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000e+00, -2.8724e-01,  6.6924e-01,  6.5114e-01, -9.8054e-01,\n",
      "         -1.1277e+00],\n",
      "        [ 7.7277e-01,  0.0000e+00,  4.5342e-02, -4.6486e-01, -9.7205e-02,\n",
      "         -5.8044e-02],\n",
      "        [ 1.4956e-01,  1.0960e-01,  0.0000e+00, -3.0034e-01, -1.1370e+00,\n",
      "         -4.7225e-01],\n",
      "        [-3.9201e-02, -5.7228e-01,  5.7727e-01,  0.0000e+00,  3.0918e-02,\n",
      "          1.9774e-05],\n",
      "        [-5.1559e-01, -7.7277e-02,  4.5326e-01, -8.6447e-02,  0.0000e+00,\n",
      "          7.1213e-01],\n",
      "        [-8.1117e-03,  1.9226e-01, -5.6347e-01, -3.1090e-01, -5.8734e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "31\n",
      "tensor([[-0.5314,  0.8761,  0.3659, -0.3793,  2.3894, -0.4553]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.2625,  0.6629,  0.6420,  0.9693,  1.1415],\n",
      "        [-0.7853,  0.0000,  0.0442, -0.4411,  0.1030,  0.0440],\n",
      "        [-0.1670, -0.0895,  0.0000, -0.2725,  1.1300,  0.4655],\n",
      "        [ 0.0269,  0.5719,  0.5750,  0.0000, -0.0273, -0.0063],\n",
      "        [ 0.5339,  0.0724,  0.4475, -0.0958,  0.0000, -0.7064],\n",
      "        [-0.0100, -0.1863, -0.5577, -0.2749,  0.5909,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "32\n",
      "tensor([[ 0.0143, -0.3761, -0.2607, -0.5918,  0.1705,  1.0158]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.2438, -0.6562,  0.6337,  0.9585, -1.1542],\n",
      "        [ 0.7978,  0.0000, -0.0431, -0.4210,  0.1078, -0.0319],\n",
      "        [ 0.1842,  0.0755,  0.0000, -0.2489,  1.1232, -0.4601],\n",
      "        [-0.0159, -0.5653, -0.5737,  0.0000, -0.0236,  0.0120],\n",
      "        [-0.5483, -0.0651, -0.4417, -0.1059,  0.0000,  0.7006],\n",
      "        [ 0.0247,  0.1692,  0.5525, -0.2385,  0.5945,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "33\n",
      "tensor([[ 1.2899,  0.7350, -1.6458,  0.9415, -3.1204, -1.1787]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.2275, -0.6521, -0.6272, -0.9458,  1.1693],\n",
      "        [ 0.8092,  0.0000, -0.0436,  0.4019, -0.1096,  0.0230],\n",
      "        [ 0.2006, -0.0633,  0.0000,  0.2283, -1.1191,  0.4525],\n",
      "        [-0.0066,  0.5599, -0.5756,  0.0000,  0.0268, -0.0142],\n",
      "        [-0.5659,  0.0604, -0.4417,  0.1124,  0.0000, -0.6836],\n",
      "        [ 0.0364, -0.1533,  0.5467,  0.2050, -0.5918,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "34\n",
      "tensor([[-0.5602, -0.8500, -0.8006,  1.2946,  0.8813,  0.2735]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.2111, -0.6489, -0.6119,  0.9324, -1.1829],\n",
      "        [-0.8201,  0.0000, -0.0441,  0.3832,  0.1114, -0.0148],\n",
      "        [-0.2161,  0.0539,  0.0000,  0.1943,  1.1155, -0.4444],\n",
      "        [-0.0021, -0.5538, -0.5780,  0.0000, -0.0300,  0.0166],\n",
      "        [ 0.5706, -0.0586, -0.4409,  0.1174,  0.0000,  0.6675],\n",
      "        [-0.0384,  0.1404,  0.5409,  0.1712,  0.5886,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "35\n",
      "tensor([[ 0.0339, -0.3110, -0.5066, -0.3411,  0.2961,  2.1994]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.1962, -0.6461,  0.5974,  0.9219, -1.1953],\n",
      "        [ 0.8319,  0.0000, -0.0486, -0.3680,  0.0995, -0.0160],\n",
      "        [ 0.2365,  0.0460,  0.0000, -0.1662,  1.0926, -0.4506],\n",
      "        [ 0.0086, -0.5487, -0.5722,  0.0000, -0.0197,  0.0280],\n",
      "        [-0.5690, -0.0563, -0.4452, -0.1247,  0.0000,  0.6423],\n",
      "        [ 0.0441,  0.1290,  0.5318, -0.1433,  0.5747,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "tensor([[-0.0813,  1.0336, -1.2932,  0.9989,  0.1520, -1.2239]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.1825, -0.6437, -0.5843,  0.9080,  1.2071],\n",
      "        [-0.8417,  0.0000, -0.0530,  0.3542,  0.0858,  0.0176],\n",
      "        [-0.2550, -0.0388,  0.0000,  0.1407,  1.0728,  0.4559],\n",
      "        [-0.0151,  0.5444, -0.5674,  0.0000, -0.0076, -0.0374],\n",
      "        [ 0.5685,  0.0542, -0.4492,  0.1314,  0.0000, -0.6193],\n",
      "        [-0.0497, -0.1185,  0.5231,  0.1173,  0.5617,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "37\n",
      "tensor([[ 0.1391, -0.8403,  0.3257, -0.4249, -0.7708,  1.5531]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.1826,  0.6415,  0.5705, -0.8958, -1.2175],\n",
      "        [ 0.8516,  0.0000,  0.0571, -0.3410, -0.0729, -0.0193],\n",
      "        [ 0.2725,  0.0311,  0.0000, -0.1196, -1.0541, -0.4602],\n",
      "        [ 0.0214, -0.5217,  0.5628,  0.0000, -0.0033,  0.0453],\n",
      "        [-0.5673, -0.0493,  0.4531, -0.1373,  0.0000,  0.5984],\n",
      "        [ 0.0546,  0.1044, -0.5151, -0.0945, -0.5498,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "38\n",
      "tensor([[ 0.8137, -1.2654, -0.4438,  1.0123,  0.3836, -0.2042]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.1876, -0.6339, -0.5573,  0.8787,  1.2137],\n",
      "        [ 0.8507,  0.0000, -0.0571,  0.3295,  0.0577,  0.0132],\n",
      "        [ 0.2804,  0.0235,  0.0000,  0.1003,  1.0353,  0.4452],\n",
      "        [ 0.0314, -0.5002, -0.5622,  0.0000,  0.0153, -0.0404],\n",
      "        [-0.5573, -0.0426, -0.4584,  0.1423,  0.0000, -0.5727],\n",
      "        [ 0.0626,  0.0904,  0.5072,  0.0742,  0.5398,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "39\n",
      "tensor([[-0.1727,  0.3710, -1.1034, -0.6620,  1.1788,  0.0108]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.1941, -0.6303,  0.5449,  0.8541, -1.2066],\n",
      "        [-0.8436,  0.0000, -0.0604, -0.3197,  0.0378, -0.0041],\n",
      "        [-0.2886, -0.0169,  0.0000, -0.0828,  1.0192, -0.4322],\n",
      "        [-0.0352,  0.4830, -0.5675,  0.0000,  0.0196,  0.0392],\n",
      "        [ 0.5518,  0.0374, -0.4646, -0.1473,  0.0000,  0.5508],\n",
      "        [-0.0652, -0.0769,  0.4984, -0.0561,  0.5261,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "40\n",
      "tensor([[ 0.3732, -0.2515, -0.4861,  2.1109, -0.0764,  0.1413]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.1993, -0.6270, -0.5333, -0.8324, -1.1971],\n",
      "        [ 0.8372,  0.0000, -0.0633,  0.3108, -0.0197,  0.0043],\n",
      "        [ 0.2956,  0.0110,  0.0000,  0.0669, -1.0041, -0.4223],\n",
      "        [ 0.0384, -0.4658, -0.5722,  0.0000, -0.0234,  0.0375],\n",
      "        [-0.5473, -0.0337, -0.4701,  0.1514,  0.0000,  0.5298],\n",
      "        [ 0.0673,  0.0642,  0.4904,  0.0393, -0.5134,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "41\n",
      "tensor([[-0.5854, -0.7467,  0.0730,  0.4016, -0.5401,  0.0647]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.2048,  0.6242, -0.5226, -0.8122, -1.1885],\n",
      "        [-0.8265,  0.0000,  0.0664,  0.3021, -0.0024,  0.0121],\n",
      "        [-0.3055,  0.0066,  0.0000,  0.0520, -0.9910, -0.4131],\n",
      "        [-0.0426, -0.4494,  0.5757,  0.0000, -0.0276,  0.0354],\n",
      "        [ 0.5410, -0.0294,  0.4749,  0.1525,  0.0000,  0.5103],\n",
      "        [-0.0773,  0.0544, -0.4837,  0.0213, -0.5028,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "42\n",
      "tensor([[ 0.0848, -0.8573,  0.3493, -0.4677,  0.8567, -1.2992]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.2085,  0.6211,  0.5130,  0.7936,  1.1751],\n",
      "        [ 0.8158,  0.0000,  0.0693, -0.2943, -0.0133, -0.0203],\n",
      "        [ 0.3177,  0.0034,  0.0000, -0.0386,  0.9789,  0.4015],\n",
      "        [ 0.0411, -0.4356,  0.5817,  0.0000,  0.0325, -0.0169],\n",
      "        [-0.5356, -0.0250,  0.4794, -0.1528,  0.0000, -0.4856],\n",
      "        [ 0.0821,  0.0452, -0.4770, -0.0041,  0.4935,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "43\n",
      "tensor([[-0.6569,  0.2245, -0.5761,  3.0700, -0.3238,  0.4312]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000e+00,  2.2148e-01, -6.1341e-01, -5.0376e-01, -7.8008e-01,\n",
      "         -1.1634e+00],\n",
      "        [-8.1315e-01,  0.0000e+00, -7.2590e-02,  2.8725e-01,  2.8137e-02,\n",
      "          2.7873e-02],\n",
      "        [-3.1868e-01,  2.0689e-04,  0.0000e+00,  2.6503e-02, -9.6767e-01,\n",
      "         -3.9094e-01],\n",
      "        [-5.5314e-02,  4.1713e-01, -5.8926e-01,  0.0000e+00, -3.4788e-02,\n",
      "          1.6521e-04],\n",
      "        [ 5.4380e-01,  2.4364e-02, -4.8245e-01,  1.5284e-01,  0.0000e+00,\n",
      "          4.6295e-01],\n",
      "        [-4.8793e-02, -2.9245e-02,  4.7331e-01, -1.1047e-02, -4.8726e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "44\n",
      "tensor([[ 0.8303, -1.5274, -1.8507,  2.6301, -1.1848,  1.4281]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.2390, -0.6065, -0.4921, -0.7677, -1.1507],\n",
      "        [ 0.8127,  0.0000, -0.0754,  0.2740,  0.0409,  0.0338],\n",
      "        [ 0.3188, -0.0057,  0.0000,  0.0185, -0.9572, -0.3822],\n",
      "        [ 0.0688, -0.3771, -0.5957,  0.0000, -0.0376, -0.0156],\n",
      "        [-0.5515, -0.0387, -0.4852,  0.1525,  0.0000,  0.4429],\n",
      "        [ 0.0186,  0.0316,  0.4701, -0.0311, -0.4818,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "45\n",
      "tensor([[ 0.0578, -1.2721,  1.5373, -2.3265,  0.7547, -0.2226]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.2561,  0.6002,  0.4906,  0.7566,  1.1387],\n",
      "        [ 0.8118,  0.0000,  0.0779, -0.2719, -0.0525, -0.0398],\n",
      "        [ 0.3168, -0.0104,  0.0000, -0.0233,  0.9474,  0.3740],\n",
      "        [ 0.0813, -0.3416,  0.6019,  0.0000,  0.0402,  0.0300],\n",
      "        [-0.5582, -0.0511,  0.4876, -0.1620,  0.0000, -0.4245],\n",
      "        [-0.0076,  0.0337, -0.4671,  0.0561,  0.4768,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "46\n",
      "tensor([[-1.2278,  0.2778, -0.0488,  0.9942,  1.2925, -0.0479]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.2709, -0.5945, -0.4900,  0.7408,  1.1273],\n",
      "        [-0.8052,  0.0000, -0.0790,  0.2704, -0.0608, -0.0453],\n",
      "        [-0.3111,  0.0143,  0.0000,  0.0275,  0.9299,  0.3654],\n",
      "        [-0.0955,  0.3087, -0.6086,  0.0000,  0.0462,  0.0434],\n",
      "        [ 0.5668,  0.0628, -0.4888,  0.1710,  0.0000, -0.4085],\n",
      "        [ 0.0307, -0.0362,  0.4641, -0.0793,  0.4717,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "47\n",
      "tensor([[ 2.0830, -0.1605, -1.9880, -0.4066,  0.5635,  0.0871]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.2843, -0.5893,  0.4846,  0.7265, -1.1170],\n",
      "        [ 0.7985,  0.0000, -0.0801, -0.2647, -0.0684,  0.0503],\n",
      "        [ 0.3077, -0.0193,  0.0000, -0.0380,  0.9141, -0.3574],\n",
      "        [ 0.1072, -0.2774, -0.6150,  0.0000,  0.0514, -0.0558],\n",
      "        [-0.5752, -0.0722, -0.4899, -0.1791,  0.0000,  0.3939],\n",
      "        [-0.0501,  0.0364,  0.4616,  0.0864,  0.4673,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "tensor([[ 0.8461, -0.1473,  0.0971, -0.9597, -1.3852,  0.3811]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.2973,  0.5851,  0.4796, -0.7139, -1.1069],\n",
      "        [ 0.7856,  0.0000,  0.0814, -0.2595,  0.0736,  0.0559],\n",
      "        [ 0.3113, -0.0244,  0.0000, -0.0474, -0.9002, -0.3513],\n",
      "        [ 0.1166, -0.2494,  0.6211,  0.0000, -0.0563, -0.0679],\n",
      "        [-0.5851, -0.0806,  0.4911, -0.1866,  0.0000,  0.3784],\n",
      "        [-0.0697,  0.0359, -0.4592,  0.0930, -0.4634,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "49\n",
      "tensor([[-1.9354,  0.2222,  0.4053, -1.6968, -0.9510,  0.7080]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.3117,  0.5661,  0.4701, -0.7040, -1.0912],\n",
      "        [-0.7756,  0.0000,  0.0858, -0.2535,  0.0788,  0.0593],\n",
      "        [-0.3044,  0.0310,  0.0000, -0.0621, -0.8889, -0.3411],\n",
      "        [-0.1201,  0.2259,  0.6115,  0.0000, -0.0615, -0.0751],\n",
      "        [ 0.5966,  0.0891,  0.4943, -0.1946,  0.0000,  0.3664],\n",
      "        [ 0.0853, -0.0360, -0.4562,  0.1010, -0.4598,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "50\n",
      "tensor([[-0.0294, -0.3040,  0.2802,  0.3468, -0.0038,  1.5120]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.3182,  0.5493, -0.4611, -0.6953, -1.0777],\n",
      "        [-0.7667,  0.0000,  0.0898,  0.2482,  0.0835,  0.0625],\n",
      "        [-0.2970, -0.0473,  0.0000,  0.0747, -0.8783, -0.3311],\n",
      "        [-0.1222, -0.2093,  0.6034,  0.0000, -0.0661, -0.0837],\n",
      "        [ 0.6070, -0.0971,  0.4973,  0.2020,  0.0000,  0.3554],\n",
      "        [ 0.0999,  0.0353, -0.4534, -0.1084, -0.4564,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "51\n",
      "tensor([[ 0.5376,  0.9076, -0.3242, -0.2360,  0.8025, -0.7143]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.3241, -0.5291,  0.4538,  0.6880,  1.0621],\n",
      "        [ 0.7587,  0.0000, -0.0944, -0.2438, -0.0883, -0.0669],\n",
      "        [ 0.2907,  0.0625,  0.0000, -0.0854,  0.8690,  0.3213],\n",
      "        [ 0.1250,  0.1943, -0.5881,  0.0000,  0.0710,  0.0908],\n",
      "        [-0.6167,  0.1043, -0.5012, -0.2091,  0.0000, -0.3454],\n",
      "        [-0.1122, -0.0345,  0.4517,  0.1177,  0.4544,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "52\n",
      "tensor([[ 1.7970, -0.4542, -0.4547,  2.1298, -0.6856,  1.5349]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.3379, -0.5107, -0.4478, -0.6798, -1.0475],\n",
      "        [ 0.7496,  0.0000, -0.0988,  0.2407,  0.0927,  0.0707],\n",
      "        [ 0.2836, -0.0659,  0.0000,  0.0954, -0.8599, -0.3123],\n",
      "        [ 0.1277, -0.1843, -0.5742,  0.0000, -0.0758, -0.0972],\n",
      "        [-0.6258, -0.1113, -0.5048,  0.2155,  0.0000,  0.3363],\n",
      "        [-0.1240,  0.0337,  0.4501, -0.1264, -0.4520,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "53\n",
      "tensor([[-0.6104, -0.2478, -0.3233,  0.0141,  0.4630,  1.0269]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.3567, -0.4961, -0.4431,  0.6671, -1.0343],\n",
      "        [-0.7435,  0.0000, -0.1028,  0.2378, -0.0966,  0.0738],\n",
      "        [-0.2736, -0.0695,  0.0000,  0.1045,  0.8514, -0.3034],\n",
      "        [-0.1176, -0.1796, -0.5647,  0.0000,  0.0767, -0.1034],\n",
      "        [ 0.6035, -0.1130, -0.5068,  0.2220,  0.0000,  0.3271],\n",
      "        [ 0.1411,  0.0312,  0.4479, -0.1345,  0.4488,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "54\n",
      "tensor([[ 0.9829, -0.9370, -0.6172,  1.5488,  1.0039, -1.3988]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.3741, -0.4820, -0.4382,  0.6520,  1.0214],\n",
      "        [ 0.7400,  0.0000, -0.1086,  0.2343, -0.1140, -0.0733],\n",
      "        [ 0.2629, -0.0733,  0.0000,  0.1139,  0.8520,  0.2924],\n",
      "        [ 0.1102, -0.1743, -0.5607,  0.0000,  0.0658,  0.1122],\n",
      "        [-0.5796, -0.1135, -0.5109,  0.2279,  0.0000, -0.3147],\n",
      "        [-0.1551,  0.0293,  0.4449, -0.1419,  0.4380,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "55\n",
      "tensor([[-1.0589,  0.5488,  1.2214, -0.4081, -2.5827,  0.1967]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  0.3894,  0.4689,  0.4227, -0.6385, -1.0093],\n",
      "        [-0.7347,  0.0000,  0.1136, -0.2403,  0.1284,  0.0731],\n",
      "        [-0.2544,  0.0770,  0.0000, -0.1122, -0.8523, -0.2826],\n",
      "        [-0.1077,  0.1707,  0.5588,  0.0000, -0.0532, -0.1209],\n",
      "        [ 0.5576,  0.1139,  0.5146, -0.2314,  0.0000,  0.3035],\n",
      "        [ 0.1711, -0.0280, -0.4425,  0.1305, -0.4285,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "56\n",
      "tensor([[ 0.6024, -0.3288, -0.2088,  0.6481, -1.5470,  0.2499]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.4056, -0.4556, -0.4076, -0.6254, -0.9698],\n",
      "        [ 0.7327,  0.0000, -0.1174,  0.2461,  0.1419,  0.0864],\n",
      "        [ 0.2480, -0.0792,  0.0000,  0.1108, -0.8524, -0.2673],\n",
      "        [ 0.1070, -0.1677, -0.5572,  0.0000, -0.0420, -0.1339],\n",
      "        [-0.5405, -0.1125, -0.5182,  0.2343,  0.0000,  0.2907],\n",
      "        [-0.1930,  0.0264,  0.4391, -0.1216, -0.4205,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "57\n",
      "tensor([[-1.0908, -0.8987,  0.6886,  0.5566, -1.1777,  0.3385]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.4185,  0.4438, -0.3667, -0.6096, -0.9340],\n",
      "        [-0.7252,  0.0000,  0.1208,  0.2800,  0.1568,  0.0985],\n",
      "        [-0.2477, -0.0826,  0.0000,  0.0815, -0.8538, -0.2540],\n",
      "        [-0.1136, -0.1678,  0.5559,  0.0000, -0.0361, -0.1462],\n",
      "        [ 0.5226, -0.1109,  0.5210,  0.2415,  0.0000,  0.2795],\n",
      "        [ 0.2111,  0.0244, -0.4360, -0.1334, -0.4137,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "58\n",
      "tensor([[-0.3553,  0.8016,  1.0765, -0.0773, -1.5741,  0.7438]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000,  0.4291,  0.4328,  0.3299, -0.5949, -0.8899],\n",
      "        [-0.7190,  0.0000,  0.1241, -0.3106,  0.1705,  0.1141],\n",
      "        [-0.2469,  0.0859,  0.0000, -0.0552, -0.8549, -0.2406],\n",
      "        [-0.1202,  0.1674,  0.5550,  0.0000, -0.0308, -0.1568],\n",
      "        [ 0.5078,  0.1098,  0.5235, -0.2485,  0.0000,  0.2627],\n",
      "        [ 0.2280, -0.0226, -0.4330,  0.1442, -0.4076,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "59\n",
      "tensor([[-0.4724,  0.4574,  0.3145, -0.6097,  0.1523, -0.5839]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.4418,  0.4256,  0.2975,  0.5804,  0.8506],\n",
      "        [-0.7197,  0.0000,  0.1102, -0.3430, -0.1785, -0.1331],\n",
      "        [-0.2477,  0.0866,  0.0000, -0.0323,  0.8567,  0.2276],\n",
      "        [-0.1251,  0.1695,  0.5577,  0.0000,  0.0250,  0.1674],\n",
      "        [ 0.4944,  0.1091,  0.5297, -0.2543,  0.0000, -0.2470],\n",
      "        [ 0.2439, -0.0204, -0.4290,  0.1544,  0.4019,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "tensor([[-1.4460,  0.7366, -1.4101,  0.4512, -0.7425,  0.7279]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.4598, -0.4171, -0.2658, -0.5630, -0.8160],\n",
      "        [-0.7212,  0.0000, -0.0854,  0.3734,  0.1863,  0.1490],\n",
      "        [-0.2501,  0.0834,  0.0000,  0.0135, -0.8572, -0.2176],\n",
      "        [-0.1288,  0.1758, -0.5697,  0.0000, -0.0202, -0.1758],\n",
      "        [ 0.4814,  0.1090, -0.5333,  0.2606,  0.0000,  0.2324],\n",
      "        [ 0.2605, -0.0157,  0.4179, -0.1669, -0.3978,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "61\n",
      "tensor([[ 0.4729, -0.6018,  0.1115,  1.0287, -1.3540, -1.4453]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.4541,  0.4096, -0.2366, -0.5475,  0.7824],\n",
      "        [ 0.7225,  0.0000,  0.0630,  0.4010,  0.1934, -0.1644],\n",
      "        [ 0.2506, -0.0889,  0.0000, -0.0036, -0.8574,  0.2104],\n",
      "        [ 0.1314, -0.1903,  0.5805,  0.0000, -0.0156,  0.1840],\n",
      "        [-0.4684, -0.1028,  0.5366,  0.2663,  0.0000, -0.2206],\n",
      "        [-0.2764,  0.0059, -0.4079, -0.1781, -0.3940,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "62\n",
      "tensor([[-0.4436, -0.9648,  0.2538,  1.1208, -1.4830,  0.5947]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.4491,  0.4030, -0.2102, -0.5335, -0.7520],\n",
      "        [-0.7242,  0.0000,  0.0518,  0.4280,  0.2017,  0.1807],\n",
      "        [-0.2497, -0.0942,  0.0000, -0.0201, -0.8580, -0.2046],\n",
      "        [-0.1335, -0.2042,  0.5807,  0.0000, -0.0128, -0.1930],\n",
      "        [ 0.4542, -0.0972,  0.5365,  0.2694,  0.0000,  0.2087],\n",
      "        [ 0.2904, -0.0029, -0.3994, -0.1876, -0.3906,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "63\n",
      "tensor([[ 0.1118, -1.5496,  0.1741, -0.7161, -1.0534,  1.2282]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.4430,  0.3970,  0.1793, -0.5201, -0.7251],\n",
      "        [ 0.7242,  0.0000,  0.0419, -0.4347,  0.2084,  0.1963],\n",
      "        [ 0.2483, -0.0999,  0.0000,  0.0389, -0.8589, -0.1989],\n",
      "        [ 0.1343, -0.2194,  0.5815,  0.0000, -0.0113, -0.1998],\n",
      "        [-0.4403, -0.0904,  0.5361, -0.2839,  0.0000,  0.1971],\n",
      "        [-0.3036, -0.0116, -0.3918,  0.2002, -0.3876,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "64\n",
      "tensor([[-1.5502, -0.0591, -0.4098,  0.6526,  0.8951,  1.3800]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.4381, -0.3905, -0.1512,  0.5077, -0.7007],\n",
      "        [-0.7364,  0.0000, -0.0349,  0.4401, -0.2137,  0.2090],\n",
      "        [-0.2318, -0.1065,  0.0000, -0.0557,  0.8592, -0.1928],\n",
      "        [-0.1218, -0.2349, -0.5789,  0.0000,  0.0094, -0.2053],\n",
      "        [ 0.4288, -0.0841, -0.5359,  0.2969,  0.0000,  0.1867],\n",
      "        [ 0.3102, -0.0190,  0.3846, -0.2118,  0.3850,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "65\n",
      "tensor([[ 0.5566, -0.5341, -0.2853, -0.2854,  0.7120,  0.6273]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.4327, -0.3853,  0.1231,  0.4992, -0.6792],\n",
      "        [ 0.7481,  0.0000, -0.0292, -0.4456, -0.2230,  0.2196],\n",
      "        [ 0.2172, -0.1123,  0.0000,  0.0696,  0.8586, -0.1882],\n",
      "        [ 0.1102, -0.2495, -0.5754,  0.0000,  0.0078, -0.2095],\n",
      "        [-0.4180, -0.0783, -0.5360, -0.3078,  0.0000,  0.1768],\n",
      "        [-0.3158, -0.0257,  0.3777,  0.2218,  0.3802,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "66\n",
      "tensor([[-0.4894, -1.1245,  0.6007, -1.2140,  1.0558,  0.1772]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.4290,  0.3810,  0.0975,  0.4905, -0.6592],\n",
      "        [-0.7590,  0.0000,  0.0241, -0.4506, -0.2329,  0.2281],\n",
      "        [-0.1959, -0.1205,  0.0000,  0.0822,  0.8591, -0.1822],\n",
      "        [-0.0978, -0.2624,  0.5723,  0.0000,  0.0058, -0.2134],\n",
      "        [ 0.4123, -0.0733,  0.5362, -0.3177,  0.0000,  0.1681],\n",
      "        [ 0.3285, -0.0322, -0.3714,  0.2307,  0.3760,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "67\n",
      "tensor([[ 0.6096,  1.0239, -0.3023,  0.3398, -1.1975, -2.5035]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.4214, -0.3747, -0.0722, -0.4817,  0.6183],\n",
      "        [ 0.7551,  0.0000, -0.0251,  0.4505,  0.2407, -0.1863],\n",
      "        [ 0.1784,  0.1285,  0.0000, -0.0924, -0.8591,  0.1535],\n",
      "        [ 0.0885,  0.2717, -0.5708,  0.0000, -0.0036,  0.2191],\n",
      "        [-0.4014,  0.0663, -0.5334,  0.3293,  0.0000, -0.1866],\n",
      "        [-0.3500,  0.0419,  0.3612, -0.2446, -0.3728,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "68\n",
      "tensor([[ 0.0328,  1.1633, -0.7350,  3.2475, -0.0273, -0.0687]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.4098, -0.3692, -0.0665, -0.4740,  0.5832],\n",
      "        [ 0.7466,  0.0000, -0.0255,  0.4312,  0.2457, -0.1456],\n",
      "        [ 0.1626,  0.1364,  0.0000, -0.0983, -0.8590,  0.1271],\n",
      "        [ 0.0777,  0.2785, -0.5694,  0.0000, -0.0017,  0.2249],\n",
      "        [-0.3943,  0.0563, -0.5307,  0.3280,  0.0000, -0.2019],\n",
      "        [-0.3671,  0.0513,  0.3520, -0.2419, -0.3700,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "69\n",
      "tensor([[-0.0318,  0.3631,  0.9645,  0.2655, -0.3016, -0.5789]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000e+00,  3.9538e-01,  3.6410e-01, -6.9638e-02, -4.6761e-01,\n",
      "          5.5227e-01],\n",
      "        [-7.3826e-01,  0.0000e+00,  2.5692e-02,  4.1188e-01,  2.4954e-01,\n",
      "         -1.0804e-01],\n",
      "        [-1.4808e-01,  1.4141e-01,  0.0000e+00, -9.6765e-02, -8.5919e-01,\n",
      "          1.0363e-01],\n",
      "        [-6.7650e-02,  2.8368e-01,  5.6800e-01,  0.0000e+00, -5.9953e-04,\n",
      "          2.3079e-01],\n",
      "        [ 3.8674e-01,  5.1670e-02,  5.2839e-01,  3.3382e-01,  0.0000e+00,\n",
      "         -2.1678e-01],\n",
      "        [ 3.8237e-01,  6.0313e-02, -3.4368e-01, -2.3865e-01, -3.6748e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "70\n",
      "tensor([[ 0.2808, -3.7572,  2.2259,  0.8793, -0.4953, -0.2273]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000e+00, -3.7941e-01,  3.6184e-01, -7.2286e-02, -4.6158e-01,\n",
      "          5.2390e-01],\n",
      "        [ 7.3148e-01,  0.0000e+00,  2.4000e-02,  3.9343e-01,  2.5202e-01,\n",
      "         -7.3369e-02],\n",
      "        [ 1.3525e-01, -1.4592e-01,  0.0000e+00, -9.5551e-02, -8.5956e-01,\n",
      "          8.2559e-02],\n",
      "        [ 5.8527e-02, -2.8745e-01,  5.6857e-01,  0.0000e+00,  6.8878e-04,\n",
      "          2.3585e-01],\n",
      "        [-3.7920e-01, -4.5248e-02,  5.2396e-01,  3.3796e-01,  0.0000e+00,\n",
      "         -2.2989e-01],\n",
      "        [-3.9653e-01, -6.7771e-02, -3.3411e-01, -2.3502e-01, -3.6479e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "tensor([[-0.3485,  0.7210,  1.7935, -1.2937,  0.9458, -0.5871]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.3660,  0.3589,  0.0747,  0.4558,  0.4989],\n",
      "        [-0.7206,  0.0000,  0.0225, -0.3749, -0.2550, -0.0407],\n",
      "        [-0.1025,  0.1513,  0.0000,  0.0941,  0.8597,  0.0645],\n",
      "        [-0.0496,  0.2920,  0.5691,  0.0000, -0.0022,  0.2411],\n",
      "        [ 0.3758,  0.0405,  0.5200, -0.3409,  0.0000, -0.2412],\n",
      "        [ 0.4099,  0.0744, -0.3255,  0.2333,  0.3625,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "72\n",
      "tensor([[ 0.7011, -1.7536,  1.7506, -0.1027, -1.0036,  0.1112]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.3575,  0.3573,  0.0774, -0.4535, -0.4769],\n",
      "        [ 0.7107,  0.0000,  0.0210, -0.3581,  0.2578,  0.0111],\n",
      "        [ 0.0731, -0.1566,  0.0000,  0.0926, -0.8585, -0.0480],\n",
      "        [ 0.0414, -0.2971,  0.5702,  0.0000,  0.0024, -0.2459],\n",
      "        [-0.3711, -0.0325,  0.5150, -0.3443,  0.0000,  0.2520],\n",
      "        [-0.4219, -0.0812, -0.3177,  0.2318, -0.3603,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "73\n",
      "tensor([[-1.4957,  0.6609,  0.1033, -1.3744,  0.4114, -0.1030]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.3497,  0.3545,  0.0797,  0.4515,  0.4499],\n",
      "        [-0.7045,  0.0000,  0.0228, -0.3414, -0.2601,  0.0312],\n",
      "        [-0.0450,  0.1612,  0.0000,  0.0903,  0.8578,  0.0128],\n",
      "        [-0.0296,  0.3023,  0.5645,  0.0000, -0.0041,  0.2245],\n",
      "        [ 0.3689,  0.0254,  0.5102, -0.3488,  0.0000, -0.2659],\n",
      "        [ 0.4299,  0.0873, -0.3083,  0.2328,  0.3586,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "74\n",
      "tensor([[-1.3767,  0.8092, -2.8622,  0.1800, -0.5623,  0.4029]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.3376, -0.3541, -0.0819, -0.4592, -0.4268],\n",
      "        [-0.6984,  0.0000, -0.0256,  0.3264,  0.2560, -0.0700],\n",
      "        [-0.0183,  0.1669,  0.0000, -0.0887, -0.8567,  0.0185],\n",
      "        [-0.0186,  0.3051, -0.5610,  0.0000,  0.0024, -0.2053],\n",
      "        [ 0.3667,  0.0200, -0.5056,  0.3528,  0.0000,  0.2786],\n",
      "        [ 0.4371,  0.0922,  0.2995, -0.2336, -0.3597,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "75\n",
      "tensor([[ 0.6630,  0.1581, -0.5095,  0.1371, -0.3872, -1.7903]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000e+00,  3.1846e-01, -3.5398e-01, -8.4885e-02, -4.6639e-01,\n",
      "          4.0601e-01],\n",
      "        [ 6.9279e-01,  0.0000e+00, -2.8179e-02,  3.1289e-01,  2.5225e-01,\n",
      "          1.0532e-01],\n",
      "        [-6.1691e-03,  1.7869e-01,  0.0000e+00, -8.7749e-02, -8.5557e-01,\n",
      "         -4.9583e-02],\n",
      "        [ 8.5567e-03,  3.0697e-01, -5.5779e-01,  0.0000e+00,  6.3137e-04,\n",
      "          1.8769e-01],\n",
      "        [-3.6477e-01,  1.2929e-02, -5.0150e-01,  3.5660e-01,  0.0000e+00,\n",
      "         -2.8900e-01],\n",
      "        [-4.4351e-01,  9.5247e-02,  2.9138e-01, -2.3371e-01, -3.6076e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "76\n",
      "tensor([[ 0.5154, -0.0793, -1.1603,  1.0689, -0.0062,  0.2289]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000e+00, -2.7924e-01, -3.5465e-01, -8.4687e-02, -4.7195e-01,\n",
      "         -3.8647e-01],\n",
      "        [ 6.8639e-01,  0.0000e+00, -3.0733e-02,  3.0192e-01,  2.4909e-01,\n",
      "         -1.3715e-01],\n",
      "        [-2.5502e-02, -2.0118e-01,  0.0000e+00, -8.0636e-02, -8.5442e-01,\n",
      "          7.8154e-02],\n",
      "        [-6.1772e-04, -3.1160e-01, -5.5509e-01,  0.0000e+00, -1.3344e-03,\n",
      "         -1.7222e-01],\n",
      "        [-3.6318e-01, -9.9105e-03, -4.9787e-01,  3.5569e-01,  0.0000e+00,\n",
      "          2.9817e-01],\n",
      "        [-4.4805e-01, -1.0388e-01,  2.8430e-01, -2.3532e-01, -3.6189e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "77\n",
      "tensor([[ 0.5650, -0.5616,  1.6530, -1.7759,  0.3421, -1.0829]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.2477,  0.3553,  0.0843,  0.4747,  0.3655],\n",
      "        [ 0.6744,  0.0000,  0.0332, -0.2922, -0.2476,  0.1642],\n",
      "        [-0.0233, -0.2180,  0.0000,  0.0753,  0.8549, -0.1009],\n",
      "        [-0.0044, -0.3139,  0.5525,  0.0000,  0.0042,  0.1593],\n",
      "        [-0.3637, -0.0076,  0.4947, -0.3561,  0.0000, -0.3068],\n",
      "        [-0.4364, -0.1081, -0.2781,  0.2387,  0.3646,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "78\n",
      "tensor([[ 2.2884,  0.4033, -0.1180,  0.3732, -1.1306, -0.6121]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.2195, -0.3586, -0.0848, -0.4815,  0.3474],\n",
      "        [ 0.6663,  0.0000, -0.0386,  0.2824,  0.2380,  0.1893],\n",
      "        [-0.0272,  0.2329,  0.0000, -0.0678, -0.8448, -0.1223],\n",
      "        [-0.0106,  0.3157, -0.5433,  0.0000,  0.0009,  0.1468],\n",
      "        [-0.3674,  0.0050, -0.4890,  0.3575,  0.0000, -0.3156],\n",
      "        [-0.4199,  0.1127,  0.2669, -0.2452, -0.3795,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "79\n",
      "tensor([[-0.6265,  1.0594,  0.1002,  0.3985, -1.9446, -0.2018]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.1931,  0.3619, -0.0925, -0.4867,  0.3303],\n",
      "        [-0.6585,  0.0000,  0.0433,  0.2649,  0.2287,  0.2126],\n",
      "        [ 0.0310,  0.2476,  0.0000, -0.0570, -0.8351, -0.1423],\n",
      "        [ 0.0156,  0.3113,  0.5332,  0.0000,  0.0012,  0.1390],\n",
      "        [ 0.3697, -0.0011,  0.4833,  0.3402,  0.0000, -0.3215],\n",
      "        [ 0.4048,  0.1166, -0.2568, -0.2511, -0.3932,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "80\n",
      "tensor([[ 0.3037,  0.1472,  0.8023, -1.6112, -0.1612, -0.9982]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000e+00,  1.6905e-01,  3.6448e-01,  1.0310e-01, -4.9153e-01,\n",
      "          3.1485e-01],\n",
      "        [ 6.5135e-01,  0.0000e+00,  4.7495e-02, -2.4058e-01,  2.1962e-01,\n",
      "          2.3409e-01],\n",
      "        [-3.3412e-02,  2.5986e-01,  0.0000e+00,  5.3989e-02, -8.2613e-01,\n",
      "         -1.6100e-01],\n",
      "        [-2.0383e-02,  3.0480e-01,  5.2383e-01,  0.0000e+00,  2.1300e-04,\n",
      "          1.3296e-01],\n",
      "        [-3.7320e-01, -8.4664e-03,  4.7910e-01, -3.1314e-01,  0.0000e+00,\n",
      "         -3.2517e-01],\n",
      "        [-3.9073e-01,  1.2154e-01, -2.4770e-01,  2.4510e-01, -4.0515e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "81\n",
      "tensor([[ 0.1810, -0.1009, -0.3334,  0.1650, -0.9588,  1.9347]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000e+00, -1.3733e-01, -3.6533e-01, -1.1153e-01, -4.9615e-01,\n",
      "         -3.0076e-01],\n",
      "        [ 6.4307e-01,  0.0000e+00, -4.8976e-02,  2.2064e-01,  2.1156e-01,\n",
      "         -2.5296e-01],\n",
      "        [-3.5813e-02, -2.5976e-01,  0.0000e+00, -5.0490e-02, -8.1811e-01,\n",
      "          1.7824e-01],\n",
      "        [-2.6606e-02, -2.8059e-01, -5.0952e-01,  0.0000e+00, -7.0271e-04,\n",
      "         -1.2698e-01],\n",
      "        [-3.7751e-01,  2.9340e-02, -4.7279e-01,  2.9074e-01,  0.0000e+00,\n",
      "          3.2891e-01],\n",
      "        [-3.7717e-01, -1.3645e-01,  2.3883e-01, -2.4170e-01, -4.1610e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "tensor([[-0.7438,  0.2242,  0.6460,  0.5392, -2.0847, -0.2981]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.1092,  0.3660, -0.1172, -0.4999,  0.2879],\n",
      "        [-0.6355,  0.0000,  0.0503,  0.2015,  0.2041,  0.2696],\n",
      "        [ 0.0378,  0.2598,  0.0000, -0.0552, -0.8112, -0.1944],\n",
      "        [ 0.0298,  0.2585,  0.4965,  0.0000, -0.0024,  0.1210],\n",
      "        [ 0.3775, -0.0484,  0.4669,  0.2680,  0.0000, -0.3326],\n",
      "        [ 0.3646,  0.1506, -0.2310, -0.2450, -0.4264,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "83\n",
      "tensor([[-0.1882, -1.5604,  0.9518,  0.2002, -0.1887,  0.8804]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.0834,  0.3550, -0.1252, -0.5061, -0.2780],\n",
      "        [-0.6288,  0.0000,  0.0485,  0.1820,  0.1969, -0.2850],\n",
      "        [ 0.0369, -0.2589,  0.0000, -0.0677, -0.8089,  0.2050],\n",
      "        [ 0.0314, -0.2377,  0.4620,  0.0000, -0.0082, -0.1187],\n",
      "        [ 0.3771,  0.0656,  0.4588,  0.2485,  0.0000,  0.3360],\n",
      "        [ 0.3547, -0.1639, -0.2149, -0.2412, -0.4336,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "84\n",
      "tensor([[-1.7990,  0.2035,  0.6181,  0.4217, -0.0240, -1.2010]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0594,  0.3451, -0.1341, -0.5115,  0.2702],\n",
      "        [-0.6227,  0.0000,  0.0469,  0.1604,  0.1902,  0.2983],\n",
      "        [ 0.0362,  0.2583,  0.0000, -0.0812, -0.8070, -0.2148],\n",
      "        [ 0.0330,  0.2191,  0.4309,  0.0000, -0.0138,  0.1164],\n",
      "        [ 0.3771, -0.0804,  0.4512,  0.2272,  0.0000, -0.3401],\n",
      "        [ 0.3455,  0.1757, -0.2005, -0.2382, -0.4401,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "85\n",
      "tensor([[-0.4348,  2.5657,  0.0117, -0.7635,  0.0690, -1.3749]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0373,  0.3369,  0.1421,  0.5173,  0.2635],\n",
      "        [-0.6173,  0.0000,  0.0430, -0.1411, -0.1842,  0.3103],\n",
      "        [ 0.0355,  0.2576,  0.0000,  0.0922,  0.8050, -0.2240],\n",
      "        [ 0.0344,  0.2024,  0.4006,  0.0000,  0.0189,  0.1144],\n",
      "        [ 0.3769, -0.0939,  0.4445, -0.2075,  0.0000, -0.3437],\n",
      "        [ 0.3370,  0.1862, -0.1892,  0.2346,  0.4458,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "86\n",
      "tensor([[-0.6695,  0.3250, -2.1381, -2.5410,  0.2362,  0.0842]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000,  0.0166, -0.3314,  0.1495,  0.5373, -0.2592],\n",
      "        [-0.6139,  0.0000, -0.0367, -0.1241, -0.1829, -0.3204],\n",
      "        [ 0.0359,  0.2565,  0.0000,  0.1022,  0.8019,  0.2315],\n",
      "        [ 0.0347,  0.1876, -0.3758,  0.0000,  0.0236, -0.1115],\n",
      "        [ 0.3765, -0.1061, -0.4383, -0.1897,  0.0000,  0.3473],\n",
      "        [ 0.3286,  0.1963,  0.1784,  0.2315,  0.4496,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "87\n",
      "tensor([[ 1.9847, -1.1441,  1.0803, -0.3174, -2.0996,  1.1919]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000e+00,  2.7483e-04,  3.2792e-01,  1.5736e-01, -5.5240e-01,\n",
      "         -2.7389e-01],\n",
      "        [ 6.1139e-01,  0.0000e+00,  3.0861e-02, -1.0890e-01,  1.8136e-01,\n",
      "         -3.2045e-01],\n",
      "        [-3.4820e-02, -2.5393e-01,  0.0000e+00,  1.1038e-01, -8.0002e-01,\n",
      "          2.5159e-01],\n",
      "        [-3.4135e-02, -1.7307e-01,  3.5271e-01,  0.0000e+00, -2.8410e-02,\n",
      "         -1.0332e-01],\n",
      "        [-3.7772e-01,  1.1618e-01,  4.3379e-01, -1.7206e-01,  0.0000e+00,\n",
      "          3.4036e-01],\n",
      "        [-3.2280e-01, -2.0799e-01, -1.6771e-01,  2.3025e-01, -4.5173e-01,\n",
      "          0.0000e+00]], grad_fn=<SubBackward0>)\n",
      "88\n",
      "tensor([[-1.0865,  0.7417, -1.4875, -0.5637,  2.6212,  0.2724]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.0042, -0.3241,  0.1649,  0.5594, -0.2770],\n",
      "        [-0.6079,  0.0000, -0.0259, -0.0951, -0.1801, -0.3206],\n",
      "        [ 0.0622,  0.2565,  0.0000,  0.1181,  0.7964,  0.2747],\n",
      "        [ 0.0239,  0.1584, -0.3321,  0.0000,  0.0335, -0.0967],\n",
      "        [ 0.3650, -0.1297, -0.4299, -0.1564,  0.0000,  0.3296],\n",
      "        [ 0.2923,  0.2130,  0.1579,  0.2285,  0.4558,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "89\n",
      "tensor([[-0.0698, -0.2652,  0.7257,  0.4255,  0.4194, -0.3139]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 10.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0051,  0.3191, -0.1717,  0.5693,  0.2767],\n",
      "        [-0.6043,  0.0000,  0.0212,  0.0826, -0.1771,  0.3213],\n",
      "        [ 0.0897, -0.2559,  0.0000, -0.1248,  0.8078, -0.2981],\n",
      "        [ 0.0152, -0.1434,  0.3129,  0.0000,  0.0421,  0.0908],\n",
      "        [ 0.3477,  0.1368,  0.4309,  0.1415,  0.0000, -0.3135],\n",
      "        [ 0.2621, -0.2164, -0.1464, -0.2273,  0.4482,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "90\n",
      "tensor([[-0.9628,  1.0968,  0.2838, -1.1199, -0.8517,  1.3133]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000, -0.0059,  0.3114,  0.1782, -0.5773, -0.2765],\n",
      "        [-0.6011,  0.0000,  0.0261, -0.0716,  0.1748, -0.3216],\n",
      "        [ 0.1103,  0.2547,  0.0000,  0.1347, -0.8150,  0.3187],\n",
      "        [ 0.0060,  0.1296,  0.2844,  0.0000, -0.0482, -0.0858],\n",
      "        [ 0.3289, -0.1444,  0.4270, -0.1258,  0.0000,  0.2993],\n",
      "        [ 0.2311,  0.2189, -0.1468,  0.2324, -0.4390,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "91\n",
      "tensor([[ 1.1386,  0.5144, -0.0487, -0.3896, -0.9306,  0.2904]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 10.]])\n",
      "tensor([[ 0.0000, -0.0079, -0.2969,  0.1838, -0.5854, -0.2791],\n",
      "        [ 0.5990,  0.0000, -0.0229, -0.0625,  0.1712, -0.3250],\n",
      "        [-0.1282,  0.2527,  0.0000,  0.1427, -0.8224,  0.3362],\n",
      "        [ 0.0015,  0.1179, -0.2672,  0.0000, -0.0524, -0.0807],\n",
      "        [-0.3123, -0.1502, -0.4267, -0.1110,  0.0000,  0.2874],\n",
      "        [-0.2029,  0.2202,  0.1492,  0.2366, -0.4308,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "92\n",
      "tensor([[ 0.2997,  1.0208, -1.3988, -0.0270, -0.7015,  0.2240]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 50.]])\n",
      "tensor([[ 0.0000, -0.0009, -0.2831,  0.1891, -0.5930, -0.2803],\n",
      "        [ 0.5982,  0.0000, -0.0204, -0.0544,  0.1680, -0.3294],\n",
      "        [-0.1453,  0.2556,  0.0000,  0.1502, -0.8293,  0.3523],\n",
      "        [ 0.0079,  0.1099, -0.2515,  0.0000, -0.0562, -0.0757],\n",
      "        [-0.2955, -0.1598, -0.4265, -0.0976,  0.0000,  0.2763],\n",
      "        [-0.1774,  0.2186,  0.1511,  0.2403, -0.4233,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "93\n",
      "tensor([[ 1.2718, -0.2155, -0.0331,  0.6108,  1.6717, -0.3789]])\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.0049, -0.2705, -0.1937,  0.5996,  0.2803],\n",
      "        [ 0.5972,  0.0000, -0.0186,  0.0471, -0.1651,  0.3359],\n",
      "        [-0.1599, -0.2606,  0.0000, -0.1572,  0.8359, -0.3601],\n",
      "        [ 0.0142, -0.1029, -0.2381,  0.0000,  0.0602,  0.0794],\n",
      "        [-0.2806,  0.1684, -0.4262,  0.0856,  0.0000, -0.2694],\n",
      "        [-0.1541, -0.2171,  0.1528, -0.2437,  0.4166,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "tensor([[-0.3348,  0.1596,  0.5248, -0.8707,  1.1715, -0.8344]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 20.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 50.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0098,  0.2594,  0.1981,  0.6055,  0.2800],\n",
      "        [-0.6044,  0.0000,  0.0175, -0.0405, -0.1638,  0.3411],\n",
      "        [ 0.1769,  0.2661,  0.0000,  0.1633,  0.8427, -0.3666],\n",
      "        [-0.0242,  0.0962,  0.2261,  0.0000,  0.0631,  0.0827],\n",
      "        [ 0.2660, -0.1766,  0.4261, -0.0744,  0.0000, -0.2633],\n",
      "        [ 0.1315,  0.2154, -0.1541,  0.2467,  0.4098,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "95\n",
      "tensor([[ 0.1478,  1.8579, -0.5939, -0.8660,  0.6082, -0.2047]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 20.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0151, -0.2472,  0.2015,  0.6026,  0.2785],\n",
      "        [ 0.6138,  0.0000, -0.0143, -0.0349, -0.1659,  0.3447],\n",
      "        [-0.1857,  0.2729,  0.0000,  0.1676,  0.8352, -0.3754],\n",
      "        [ 0.0316,  0.0894, -0.2183,  0.0000,  0.0680,  0.0867],\n",
      "        [-0.2460, -0.1817, -0.4213, -0.0657,  0.0000, -0.2607],\n",
      "        [-0.1131,  0.2133,  0.1529,  0.2502,  0.4092,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "96\n",
      "tensor([[ 0.3949, -0.0776,  1.1912,  2.2507, -1.9511, -1.1371]])\n",
      "tensor([[20.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 50.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000, -0.0168,  0.2360, -0.2045, -0.6000,  0.2772],\n",
      "        [ 0.6226,  0.0000,  0.0118,  0.0302,  0.1666,  0.3474],\n",
      "        [-0.1942, -0.2798,  0.0000, -0.1715, -0.8264, -0.3838],\n",
      "        [ 0.0384, -0.0841,  0.2111,  0.0000, -0.0731,  0.0904],\n",
      "        [-0.2281,  0.1951,  0.4174,  0.0580,  0.0000, -0.2593],\n",
      "        [-0.0968, -0.2149, -0.1518, -0.2533, -0.4084,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "97\n",
      "tensor([[ 0.0887,  1.1855, -0.0656, -0.2914, -2.0883,  0.9035]])\n",
      "tensor([[10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 50.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., 20.]])\n",
      "tensor([[ 0.0000,  0.0191, -0.2264,  0.2098, -0.5974, -0.2763],\n",
      "        [ 0.6293,  0.0000, -0.0097, -0.0291,  0.1676, -0.3494],\n",
      "        [-0.1992,  0.2857,  0.0000,  0.1953, -0.8188,  0.3904],\n",
      "        [ 0.0448,  0.0793, -0.2044,  0.0000, -0.0778, -0.0940],\n",
      "        [-0.2123, -0.2070, -0.4139, -0.0418,  0.0000,  0.2567],\n",
      "        [-0.0846,  0.2168,  0.1506,  0.2435, -0.4075,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "98\n",
      "tensor([[-0.5450,  1.0095,  1.0446,  0.9338, -1.3459, -1.1447]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 10.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0227,  0.2177, -0.2146, -0.5951,  0.2741],\n",
      "        [-0.6352,  0.0000,  0.0079,  0.0283,  0.1686,  0.3500],\n",
      "        [ 0.2034,  0.2896,  0.0000, -0.2166, -0.8114, -0.3988],\n",
      "        [-0.0506,  0.0794,  0.1983,  0.0000, -0.0822,  0.0978],\n",
      "        [ 0.1966, -0.2223,  0.4109,  0.0271,  0.0000, -0.2543],\n",
      "        [ 0.0728,  0.2255, -0.1500, -0.2352, -0.4073,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "99\n",
      "tensor([[-1.0262,  0.5248,  0.7715,  0.3109, -1.0829, -1.3064]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 50.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 20.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "tensor([[ 0.0000,  0.0268,  0.2079, -0.2191, -0.5928,  0.2721],\n",
      "        [-0.6406,  0.0000,  0.0042,  0.0270,  0.1693,  0.3507],\n",
      "        [ 0.2073,  0.2928,  0.0000, -0.2358, -0.8044, -0.4067],\n",
      "        [-0.0559,  0.0775,  0.1881,  0.0000, -0.0863,  0.1013],\n",
      "        [ 0.1822, -0.2358,  0.4075,  0.0136,  0.0000, -0.2519],\n",
      "        [ 0.0622,  0.2352, -0.1478, -0.2259, -0.4071,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#this is to learn and simulate \n",
    "#E and I neurons mixed randomly \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "n=6\n",
    "tao=100\n",
    "dt = 1e-4\n",
    "T=int(10/dt)\n",
    "B=10\n",
    "w=torch.randn(n,n, device='cpu', requires_grad=True,dtype=torch.float)\n",
    "lr = 1e-1\n",
    "n_epochs = 100\n",
    "\n",
    "optimizer = optim.Adam([w], lr=lr)\n",
    "V=torch.zeros(T,n)\n",
    "ep=np.arange(n_epochs)\n",
    "Loss=torch.zeros(n_epochs,)\n",
    "Wmean=torch.zeros(n_epochs,)\n",
    "#P=(np.absolute(np.random.randint(low=1, high=100, size=math.ceil(n/2))))\n",
    "P=np.array([50,20,10])\n",
    "for epoch in range(n_epochs):\n",
    "    print (epoch)\n",
    "    #generate a panda dataframe consists the values and class E of the neuron, assign 1 to the data \n",
    "    ze = pd.DataFrame({'Value': torch.from_numpy(np.absolute(np.array(np.random.normal(0, 1, math.ceil(n/2))))),\n",
    "                    'Type': 'E',\n",
    "                    'sign': np.array([1] * math.ceil(n/2), dtype='int32'),\n",
    "                   'penalty':torch.from_numpy(P)\n",
    "                    })  \n",
    "     #generate a panda dataframe consists the values and class I of the neuron, assign -1 to the data \n",
    "    zi = pd.DataFrame({'Value': torch.from_numpy(-np.absolute(np.array(np.random.normal(0, 1, round(n/2))))),\n",
    "                    'Type': 'I',\n",
    "                    'sign': np.array([-1] * round(n/2), dtype='int32'),\n",
    "                   'penalty':torch.from_numpy((np.array([1] * round(n/2))))\n",
    "                   })   \n",
    "    #join E neurons and I neuronns \n",
    "    zf = pd.concat([ze, zi])\n",
    "    #mix the joint population \n",
    "    zd = zf.sample(frac=1).reset_index(drop=True)\n",
    "    #convert the panda dataframe to a tensor \n",
    "    z=torch.zeros(1,n)\n",
    "    #p=torch.zeros(1,n)\n",
    "    p=np.zeros(n)\n",
    "    for d in range(n):\n",
    "        z[:,d]=(zd.loc[d,'Value'])\n",
    "    print(z)\n",
    "    for e in range(n):\n",
    "        p[e]=(zd.loc[e,'penalty'])        \n",
    "    \n",
    "    \n",
    "    #create a new tensor to prevent the leaf variable go into the learning process  \n",
    "    p2=torch.from_numpy(p)\n",
    "    p3=torch.diag(p2)\n",
    "    p1=p3.type(dtype=torch.float)\n",
    "    print (p1)\n",
    "    wi=torch.randn(n,n)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            #print (z.loc[j,'sign'])\n",
    "            #print (w[i,j])\n",
    "            wi[i,j]=(zd.loc[j,'sign'])*w[i,j]\n",
    "            #print (w[i,j])\n",
    "    \n",
    "    w1=torch.diag(wi)\n",
    "    w_rec=torch.diag(w1)\n",
    "    w1_rec = wi-w_rec\n",
    "    print (w1_rec)\n",
    "    \n",
    "    loss=0\n",
    "    for t in range(T):\n",
    "        N=torch.randn(1,n)\n",
    "        z_dot=(-z+(z@w1_rec)/math.sqrt(n))\n",
    "        z = z + z_dot*dt+N*math.sqrt(dt)\n",
    "        loss = loss + ((z@p1)**2).mean()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    Loss[epoch]=loss\n",
    "   \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this is to plot the graph \n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:mint green')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.title('Learning curve')\n",
    "df=pd.DataFrame(Loss.detach().numpy())\n",
    "rolling_mean = df.rolling(window=10).mean()\n",
    "plt.plot(ep, rolling_mean, label='Learning Curve', color='k')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 1.1284,  0.3792,  1.8878, -0.6107, -0.0738, -0.9277])\n",
      "1\n",
      "tensor([ 2.7219,  2.0024,  0.9695, -0.3387, -1.0788, -0.0732])\n",
      "2\n",
      "tensor([ 0.2856,  0.0740,  0.3217, -0.5727, -0.8471, -0.5088])\n",
      "3\n",
      "tensor([ 0.4501,  0.1181,  2.0602, -0.2805, -1.4058, -1.3236])\n",
      "4\n",
      "tensor([ 0.6407,  1.3741,  1.0238, -0.4060, -0.3386, -0.8964])\n",
      "5\n",
      "tensor([ 0.6670,  1.1786,  0.0584, -0.8967, -0.4819, -0.5378])\n",
      "6\n",
      "tensor([ 0.1672,  0.8577,  1.7054, -0.0998, -0.5367, -0.3212])\n",
      "7\n",
      "tensor([ 1.9293,  0.8097,  0.9658, -1.5582, -0.0723, -0.5205])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50, 20, 10,  1,  1,  1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:mint green')\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('Penalty')\n",
    "plt.title('Variance vs Penalty')\n",
    "plt.grid(True)\n",
    "color=['b','c','k','g','w','m','r','y']\n",
    "for a in range(8):\n",
    "    print (a)\n",
    "    #generate a panda dataframe consists the values and class E of the neuron, assign 1 to the data \n",
    "    ze = pd.DataFrame({'Value': torch.from_numpy(np.absolute(np.array(np.random.normal(0, 1, math.ceil(n/2))))),\n",
    "                    'Type': 'E',\n",
    "                    'sign': np.array([1] * math.ceil(n/2), dtype='int32')})  \n",
    "     #generate a panda dataframe consists the values and class I of the neuron, assign -1 to the data \n",
    "    zi = pd.DataFrame({'Value': torch.from_numpy(-np.absolute(np.array(np.random.normal(0, 1, round(n/2))))),\n",
    "                    'Type': 'I',\n",
    "                    'sign': np.array([-1] * round(n/2), dtype='int32')})   \n",
    "    #join E neurons and I neuronns \n",
    "    zf = pd.concat([ze, zi]).reset_index(drop=True)\n",
    "    #mix the joint population \n",
    "    #zd = zf.sample(frac=1).reset_index(drop=True)\n",
    "    #convert the panda dataframe to a tensor \n",
    "    #print (ze,zi,zf,zd)\n",
    "    z1=np.zeros(n)\n",
    "  \n",
    "    for m in range(n):\n",
    "        z1[m]=(zf.loc[m,'Value'])\n",
    "        \n",
    "\n",
    "    z2=torch.from_numpy(z1)\n",
    "    z=z2.type(dtype=torch.float)\n",
    "        \n",
    "\n",
    "    Z=torch.zeros(T,n)\n",
    "    print (z)\n",
    "   \n",
    "    \n",
    "    for t in range(T):\n",
    "        N=torch.randn(1,n)\n",
    "        z_dot=(-z+(z@w1_rec)/math.sqrt(n))\n",
    "        z = z + z_dot*dt+N*math.sqrt(dt)\n",
    "        Z[t] = z\n",
    "        Z_split = torch.split(Z,int(T/2),dim=0)[1]\n",
    "        \n",
    "    V=torch.zeros(n,1)\n",
    "    P1=torch.from_numpy(np.append(P,[1,1,1]))\n",
    "\n",
    "    for i in range(n):\n",
    "        V[i]=torch.var(Z_split[:,i])  \n",
    "        \n",
    "    plt.scatter(P1,V.detach().numpy(),color=color[a])   \n",
    "    plt.plot(P1.detach().numpy(),V.detach().numpy(),color=color[a]) \n",
    "    \n",
    "plt.show() \n",
    "print (P1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
