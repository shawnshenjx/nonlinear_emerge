{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345],\n",
      "        [-0.0431, -1.6047, -0.7521,  1.6487, -0.3925, -1.4036],\n",
      "        [-0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596],\n",
      "        [-0.4974,  0.4396,  0.3189, -0.4245,  0.3057, -0.7746],\n",
      "        [ 0.0349,  0.3211,  1.5736, -0.8455, -1.2742,  2.1228],\n",
      "        [-1.2347, -0.4879, -1.4181,  0.8963,  0.0499,  2.2667]],\n",
      "       requires_grad=True)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "0\n",
      "tensor([ 1.8677,  0.4459,  0.4799, -0.3288, -0.7781, -0.7135])\n",
      "tensor([[ 0.0000,  1.6910,  1.2417, -0.1149, -1.0888, -0.2554],\n",
      "        [ 0.6718,  0.0000,  0.3862, -1.8246, -0.5160, -0.2197],\n",
      "        [ 0.3940,  0.4521,  0.0000, -1.1453, -1.8192, -0.6165],\n",
      "        [ 0.4751,  0.9369,  0.8652,  0.0000, -0.8576, -0.3790],\n",
      "        [ 0.7108,  0.8665,  1.7620, -0.3572,  0.0000, -2.2358],\n",
      "        [ 0.2554,  0.4787,  0.2169, -1.2385, -0.7184,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "1\n",
      "tensor([ 0.0364,  1.0297,  0.3145, -0.9161, -1.2702, -0.7158])\n",
      "tensor([[ 0.0000,  1.6102,  1.1716, -0.1263, -1.1563, -0.2788],\n",
      "        [ 0.6242,  0.0000,  0.3552, -1.7414, -0.4769, -0.2402],\n",
      "        [ 0.3625,  0.4168,  0.0000, -1.2146, -1.9037, -0.6638],\n",
      "        [ 0.5141,  0.9989,  0.8086,  0.0000, -0.9164, -0.4117],\n",
      "        [ 0.7629,  0.9257,  1.8455, -0.3282,  0.0000, -2.1470],\n",
      "        [ 0.2337,  0.4418,  0.2372, -1.3105, -0.7709,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "2\n",
      "tensor([ 2.1367e-01,  1.5898e+00,  2.7405e-01, -1.0756e-03, -3.9613e-01,\n",
      "        -1.4289e+00])\n",
      "tensor([[ 0.0000,  1.5313,  1.1080, -0.1385, -1.2227, -0.3032],\n",
      "        [ 0.6094,  0.0000,  0.3265, -1.6641, -0.4401, -0.2612],\n",
      "        [ 0.3397,  0.3983,  0.0000, -1.2229, -1.8896, -0.7119],\n",
      "        [ 0.4863,  0.9633,  0.8383,  0.0000, -0.9635, -0.3931],\n",
      "        [ 0.7797,  0.9528,  1.9233, -0.3297,  0.0000, -2.0740],\n",
      "        [ 0.2484,  0.4671,  0.2577, -1.2917, -0.7848,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "3\n",
      "tensor([ 0.7526,  1.7304,  0.2909, -0.6886, -0.3146, -0.3576])\n",
      "tensor([[ 0.0000,  1.4579,  1.0636, -0.1516, -1.2924, -0.3253],\n",
      "        [ 0.5788,  0.0000,  0.3024, -1.6952, -0.4364, -0.2826],\n",
      "        [ 0.3168,  0.3745,  0.0000, -1.2579, -1.9196, -0.7402],\n",
      "        [ 0.4964,  0.9768,  0.8514,  0.0000, -0.9539, -0.3747],\n",
      "        [ 0.8007,  0.9620,  1.9462, -0.3309,  0.0000, -2.0417],\n",
      "        [ 0.2420,  0.4953,  0.2784, -1.3016, -0.8217,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "4\n",
      "tensor([ 0.1229,  0.7139,  0.0348, -0.0731, -0.3661, -0.3994])\n",
      "tensor([[ 0.0000,  1.3865,  1.0127, -0.1660, -1.3645, -0.3508],\n",
      "        [ 0.5483,  0.0000,  0.2795, -1.7215, -0.4248, -0.3065],\n",
      "        [ 0.3093,  0.3596,  0.0000, -1.2543, -1.9001, -0.7787],\n",
      "        [ 0.4915,  0.9783,  0.8828,  0.0000, -0.9675, -0.3525],\n",
      "        [ 0.7973,  0.9701,  1.9863, -0.3402,  0.0000, -2.0031],\n",
      "        [ 0.2477,  0.5231,  0.2993, -1.2686, -0.8310,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "5\n",
      "tensor([ 1.0455,  0.1506,  0.7541, -2.6710, -0.6162, -0.1442])\n",
      "tensor([[ 0.0000,  1.3211,  0.9616, -0.1815, -1.4375, -0.3780],\n",
      "        [ 0.5270,  0.0000,  0.2597, -1.7348, -0.4106, -0.3275],\n",
      "        [ 0.2953,  0.3402,  0.0000, -1.2721, -1.9091, -0.8171],\n",
      "        [ 0.4854,  0.9769,  0.8970,  0.0000, -0.9818, -0.3404],\n",
      "        [ 0.7772,  0.9620,  2.0325, -0.3572,  0.0000, -1.9580],\n",
      "        [ 0.2606,  0.5564,  0.3215, -1.2211, -0.8094,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "6\n",
      "tensor([ 0.2221,  1.7912,  0.0759, -0.0507, -0.5535, -0.0138])\n",
      "tensor([[ 0.0000,  1.2605,  0.9173, -0.1979, -1.5120, -0.4067],\n",
      "        [ 0.4999,  0.0000,  0.2455, -1.7755, -0.4193, -0.3517],\n",
      "        [ 0.2820,  0.3203,  0.0000, -1.2916, -1.9165, -0.8619],\n",
      "        [ 0.4854,  0.9695,  0.9122,  0.0000, -0.9921, -0.3271],\n",
      "        [ 0.7703,  0.9759,  2.0577, -0.3683,  0.0000, -1.9107],\n",
      "        [ 0.2711,  0.5731,  0.3460, -1.1889, -0.7972,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "7\n",
      "tensor([ 0.6641,  2.4092,  0.5942, -1.0753, -0.1712, -0.4865])\n",
      "tensor([[ 0.0000,  1.1997,  0.8864, -0.2162, -1.5893, -0.4374],\n",
      "        [ 0.4724,  0.0000,  0.2338, -1.8266, -0.4312, -0.3790],\n",
      "        [ 0.2691,  0.3045,  0.0000, -1.3129, -1.9281, -0.9019],\n",
      "        [ 0.4830,  0.9663,  0.9306,  0.0000, -1.0064, -0.3153],\n",
      "        [ 0.7666,  0.9826,  2.0920, -0.3794,  0.0000, -1.8642],\n",
      "        [ 0.2817,  0.5895,  0.3654, -1.1565, -0.7835,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "8\n",
      "tensor([ 0.6486,  1.3455,  0.0793, -1.7882, -0.1520, -0.9258])\n",
      "tensor([[ 0.0000,  1.1430,  0.8479, -0.2361, -1.6662, -0.4708],\n",
      "        [ 0.4529,  0.0000,  0.2207, -1.8631, -0.4333, -0.4067],\n",
      "        [ 0.2551,  0.2902,  0.0000, -1.3378, -1.9452, -0.9434],\n",
      "        [ 0.4744,  0.9568,  0.9374,  0.0000, -1.0258, -0.3173],\n",
      "        [ 0.7491,  0.9887,  2.1447, -0.3976,  0.0000, -1.8319],\n",
      "        [ 0.2958,  0.6040,  0.3813, -1.1183, -0.7631,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "9\n",
      "tensor([ 0.3467,  0.7809,  0.3540, -0.1939, -0.8765, -0.6701])\n",
      "tensor([[ 0.0000,  1.0898,  0.8313, -0.2579, -1.7444, -0.5064],\n",
      "        [ 0.4426,  0.0000,  0.2087, -1.8894, -0.4302, -0.4320],\n",
      "        [ 0.2423,  0.2742,  0.0000, -1.3686, -1.9690, -0.9838],\n",
      "        [ 0.4627,  0.9443,  0.9504,  0.0000, -1.0516, -0.3211],\n",
      "        [ 0.7474,  1.0018,  2.1717, -0.4085,  0.0000, -1.7904],\n",
      "        [ 0.3074,  0.6217,  0.3952, -1.0840, -0.7449,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "10\n",
      "tensor([ 0.8180,  0.7991,  0.5710, -0.3057, -0.6635, -2.0319])\n",
      "tensor([[ 0.0000,  1.0421,  0.8112, -0.2815, -1.8226, -0.5453],\n",
      "        [ 0.4328,  0.0000,  0.1995, -1.9165, -0.4298, -0.4565],\n",
      "        [ 0.2337,  0.2617,  0.0000, -1.3880, -1.9821, -1.0113],\n",
      "        [ 0.4547,  0.9315,  0.9731,  0.0000, -1.0737, -0.3199],\n",
      "        [ 0.7462,  1.0163,  2.1811, -0.4167,  0.0000, -1.7515],\n",
      "        [ 0.3172,  0.6343,  0.4097, -1.0581, -0.7316,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "11\n",
      "tensor([ 0.7866,  0.9284,  0.5620, -0.3318, -0.4668, -2.2858])\n",
      "tensor([[ 0.0000,  0.9920,  0.7969, -0.3073, -1.9042, -0.5873],\n",
      "        [ 0.4186,  0.0000,  0.1908, -1.9534, -0.4343, -0.4857],\n",
      "        [ 0.2263,  0.2503,  0.0000, -1.4018, -1.9885, -1.0361],\n",
      "        [ 0.4445,  0.9118,  0.9919,  0.0000, -1.0998, -0.3248],\n",
      "        [ 0.7441,  1.0290,  2.1911, -0.4264,  0.0000, -1.7235],\n",
      "        [ 0.3332,  0.6590,  0.4152, -1.0219, -0.7107,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "12\n",
      "tensor([ 0.7045,  0.3099,  0.8363, -1.1366, -1.6146, -0.9502])\n",
      "tensor([[ 0.0000,  0.9477,  0.7900, -0.3343, -1.9852, -0.6315],\n",
      "        [ 0.4048,  0.0000,  0.1829, -1.9903, -0.4403, -0.5159],\n",
      "        [ 0.2215,  0.2402,  0.0000, -1.4092, -1.9876, -1.0501],\n",
      "        [ 0.4352,  0.8902,  1.0082,  0.0000, -1.1242, -0.3307],\n",
      "        [ 0.7392,  1.0413,  2.2075, -0.4365,  0.0000, -1.7052],\n",
      "        [ 0.3487,  0.6832,  0.4236, -0.9897, -0.6924,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "13\n",
      "tensor([ 0.0384,  0.0554,  1.4026, -0.5419, -0.3663, -0.6363])\n",
      "tensor([[ 0.0000,  0.9105,  0.7889, -0.3633, -2.0685, -0.6791],\n",
      "        [ 0.3989,  0.0000,  0.1738, -2.0155, -0.4397, -0.5330],\n",
      "        [ 0.2171,  0.2306,  0.0000, -1.4170, -1.9861, -1.0631],\n",
      "        [ 0.4266,  0.8699,  1.0268,  0.0000, -1.1481, -0.3380],\n",
      "        [ 0.7399,  1.0413,  2.2205, -0.4447,  0.0000, -1.6876],\n",
      "        [ 0.3608,  0.7024,  0.4300, -0.9658, -0.6788,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "14\n",
      "tensor([ 0.4384,  1.2789,  1.8607, -2.4637, -0.6928, -1.2760])\n",
      "tensor([[ 0.0000,  0.8723,  0.7925, -0.3947, -2.1533, -0.7304],\n",
      "        [ 0.3893,  0.0000,  0.1662, -2.0476, -0.4440, -0.5566],\n",
      "        [ 0.2131,  0.2210,  0.0000, -1.4280, -1.9877, -1.0704],\n",
      "        [ 0.4163,  0.8487,  1.0589,  0.0000, -1.1769, -0.3522],\n",
      "        [ 0.7438,  1.0488,  2.2193, -0.4495,  0.0000, -1.6564],\n",
      "        [ 0.3683,  0.7175,  0.4439, -0.9467, -0.6681,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "15\n",
      "tensor([ 0.2040,  2.0769,  0.2698, -1.1903, -1.8569, -0.3539])\n",
      "tensor([[ 0.0000,  0.8373,  0.7960, -0.4279, -2.2379, -0.7849],\n",
      "        [ 0.3806,  0.0000,  0.1588, -2.0819, -0.4490, -0.5795],\n",
      "        [ 0.2090,  0.2141,  0.0000, -1.4380, -1.9901, -1.0778],\n",
      "        [ 0.4114,  0.8309,  1.0942,  0.0000, -1.1989, -0.3617],\n",
      "        [ 0.7554,  1.0511,  2.2135, -0.4519,  0.0000, -1.6159],\n",
      "        [ 0.3763,  0.7301,  0.4618, -0.9294, -0.6589,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "16\n",
      "tensor([ 1.3017,  0.5349,  1.8042, -0.2134, -1.3620, -0.3519])\n",
      "tensor([[ 0.0000,  0.8030,  0.8030, -0.4629, -2.3204, -0.8430],\n",
      "        [ 0.3739,  0.0000,  0.1528, -2.1111, -0.4521, -0.5997],\n",
      "        [ 0.2049,  0.2099,  0.0000, -1.4467, -1.9899, -1.0773],\n",
      "        [ 0.4023,  0.8057,  1.1334,  0.0000, -1.2285, -0.3784],\n",
      "        [ 0.7715,  1.0626,  2.1837, -0.4531,  0.0000, -1.5640],\n",
      "        [ 0.3836,  0.7484,  0.4779, -0.9130, -0.6504,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "17\n",
      "tensor([ 0.7180,  1.1224,  0.5134, -0.6348, -0.3197, -0.1608])\n",
      "tensor([[ 0.0000,  0.7660,  0.8216, -0.5011, -2.4068, -0.8965],\n",
      "        [ 0.3601,  0.0000,  0.1517, -2.1531, -0.4664, -0.6284],\n",
      "        [ 0.2034,  0.2076,  0.0000, -1.4472, -1.9748, -1.0561],\n",
      "        [ 0.3937,  0.7845,  1.1765,  0.0000, -1.2577, -0.3960],\n",
      "        [ 0.7825,  1.0659,  2.1499, -0.4590,  0.0000, -1.5198],\n",
      "        [ 0.3994,  0.7725,  0.4805, -0.8913, -0.6344,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "18\n",
      "tensor([ 0.1954,  1.1492,  1.8139, -0.1242, -1.0233, -1.4223])\n",
      "tensor([[ 0.0000,  0.7313,  0.8386, -0.5402, -2.4890, -0.9500],\n",
      "        [ 0.3493,  0.0000,  0.1502, -2.1883, -0.4783, -0.6522],\n",
      "        [ 0.2031,  0.2049,  0.0000, -1.4481, -1.9553, -1.0265],\n",
      "        [ 0.3815,  0.7642,  1.2286,  0.0000, -1.2910, -0.4193],\n",
      "        [ 0.7968,  1.0734,  2.1102, -0.4645,  0.0000, -1.4708],\n",
      "        [ 0.4145,  0.7975,  0.4882, -0.8700, -0.6200,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "19\n",
      "tensor([ 0.0306,  0.9551,  0.0482, -0.8018, -0.7590, -1.6080])\n",
      "tensor([[ 0.0000,  0.6983,  0.8598, -0.5810, -2.5736, -1.0085],\n",
      "        [ 0.3390,  0.0000,  0.1485, -2.2211, -0.4893, -0.6751],\n",
      "        [ 0.2015,  0.2015,  0.0000, -1.4450, -1.9446, -1.0190],\n",
      "        [ 0.3710,  0.7451,  1.2712,  0.0000, -1.3199, -0.4373],\n",
      "        [ 0.8075,  1.0837,  2.0784, -0.4708,  0.0000, -1.4319],\n",
      "        [ 0.4313,  0.8255,  0.4945, -0.8505, -0.6050,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "20\n",
      "tensor([ 0.3021,  0.0769,  0.2403, -1.7269, -1.4194, -1.6024])\n",
      "tensor([[ 0.0000,  0.6722,  0.8765, -0.6233, -2.6553, -1.0643],\n",
      "        [ 0.3297,  0.0000,  0.1482, -2.2511, -0.5015, -0.7018],\n",
      "        [ 0.2006,  0.1991,  0.0000, -1.4401, -1.9314, -1.0080],\n",
      "        [ 0.3615,  0.7258,  1.3208,  0.0000, -1.3515, -0.4578],\n",
      "        [ 0.8233,  1.0828,  2.0458, -0.4750,  0.0000, -1.3972],\n",
      "        [ 0.4496,  0.8532,  0.4990, -0.8317, -0.5898,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "21\n",
      "tensor([ 0.6365,  1.8449,  0.7727, -0.9721, -0.5515, -0.2795])\n",
      "tensor([[ 0.0000,  0.6489,  0.8907, -0.6654, -2.7312, -1.1176],\n",
      "        [ 0.3217,  0.0000,  0.1479, -2.2780, -0.5128, -0.7260],\n",
      "        [ 0.1998,  0.1967,  0.0000, -1.4371, -1.9187, -0.9966],\n",
      "        [ 0.3534,  0.7085,  1.3598,  0.0000, -1.3780, -0.4732],\n",
      "        [ 0.8385,  1.0830,  2.0163, -0.4792,  0.0000, -1.3635],\n",
      "        [ 0.4670,  0.8754,  0.5012, -0.8157, -0.5762,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "22\n",
      "tensor([ 0.5965,  0.1980,  1.1610, -2.2236, -1.1538, -0.7614])\n",
      "tensor([[ 0.0000,  0.6291,  0.9047, -0.7070, -2.8053, -1.1716],\n",
      "        [ 0.3150,  0.0000,  0.1474, -2.3038, -0.5223, -0.7461],\n",
      "        [ 0.1978,  0.1946,  0.0000, -1.4338, -1.9150, -0.9973],\n",
      "        [ 0.3489,  0.6917,  1.3934,  0.0000, -1.3947, -0.4809],\n",
      "        [ 0.8495,  1.0775,  1.9911, -0.4858,  0.0000, -1.3390],\n",
      "        [ 0.4819,  0.8964,  0.5060, -0.7992, -0.5656,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "23\n",
      "tensor([ 0.0738,  0.8701,  0.4139, -1.0447, -0.1460, -0.8814])\n",
      "tensor([[ 0.0000,  0.6103,  0.9196, -0.7461, -2.8759, -1.2266],\n",
      "        [ 0.3080,  0.0000,  0.1474, -2.3272, -0.5329, -0.7701],\n",
      "        [ 0.1958,  0.1925,  0.0000, -1.4291, -1.9142, -1.0038],\n",
      "        [ 0.3465,  0.6787,  1.4162,  0.0000, -1.4061, -0.4824],\n",
      "        [ 0.8657,  1.0808,  1.9611, -0.4921,  0.0000, -1.3014],\n",
      "        [ 0.4962,  0.9121,  0.5098, -0.7854, -0.5555,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "24\n",
      "tensor([ 1.8466,  1.0622,  0.2072, -0.2859, -0.3737, -0.3952])\n",
      "tensor([[ 0.0000,  0.5916,  0.9374, -0.7866, -2.9505, -1.2885],\n",
      "        [ 0.3010,  0.0000,  0.1464, -2.3611, -0.5443, -0.7922],\n",
      "        [ 0.1932,  0.1899,  0.0000, -1.4346, -1.9194, -1.0106],\n",
      "        [ 0.3493,  0.6725,  1.4444,  0.0000, -1.4019, -0.4766],\n",
      "        [ 0.8699,  1.0831,  1.9409, -0.4992,  0.0000, -1.2895],\n",
      "        [ 0.5092,  0.9271,  0.5208, -0.7691, -0.5490,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "25\n",
      "tensor([ 0.8007,  0.5117,  0.5194, -0.4709, -0.4831, -1.6590])\n",
      "tensor([[ 0.0000,  0.5706,  0.9566, -0.8304, -3.0285, -1.3577],\n",
      "        [ 0.2910,  0.0000,  0.1453, -2.4055, -0.5642, -0.8278],\n",
      "        [ 0.1886,  0.1852,  0.0000, -1.4479, -1.9389, -1.0347],\n",
      "        [ 0.3531,  0.6681,  1.4812,  0.0000, -1.3937, -0.4691],\n",
      "        [ 0.8699,  1.0769,  1.9212, -0.5077,  0.0000, -1.2919],\n",
      "        [ 0.5260,  0.9505,  0.5287, -0.7536, -0.5401,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "26\n",
      "tensor([ 1.1850,  0.0069,  0.8388, -0.8125, -0.4059, -1.5171])\n",
      "tensor([[ 0.0000,  0.5515,  0.9765, -0.8729, -3.1039, -1.4283],\n",
      "        [ 0.2812,  0.0000,  0.1437, -2.4515, -0.5848, -0.8644],\n",
      "        [ 0.1852,  0.1815,  0.0000, -1.4631, -1.9495, -1.0435],\n",
      "        [ 0.3557,  0.6619,  1.5132,  0.0000, -1.3907, -0.4645],\n",
      "        [ 0.8785,  1.0727,  1.8922, -0.5184,  0.0000, -1.2779],\n",
      "        [ 0.5375,  0.9680,  0.5438, -0.7362, -0.5342,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "27\n",
      "tensor([ 0.1271,  0.9972,  0.6886, -0.4904, -0.3076, -0.3668])\n",
      "tensor([[ 0.0000,  0.5324,  1.0027, -0.9132, -3.1834, -1.5064],\n",
      "        [ 0.2706,  0.0000,  0.1428, -2.4981, -0.6088, -0.9074],\n",
      "        [ 0.1838,  0.1797,  0.0000, -1.4814, -1.9488, -1.0319],\n",
      "        [ 0.3560,  0.6554,  1.5514,  0.0000, -1.3944, -0.4687],\n",
      "        [ 0.9019,  1.0735,  1.8479, -0.5326,  0.0000, -1.2415],\n",
      "        [ 0.5429,  0.9776,  0.5666, -0.7172, -0.5316,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "28\n",
      "tensor([ 0.1522,  0.7622,  0.1335, -0.8446, -1.7226, -2.1789])\n",
      "tensor([[ 0.0000,  0.5129,  1.0352, -0.9460, -3.2627, -1.5901],\n",
      "        [ 0.2589,  0.0000,  0.1455, -2.5351, -0.6404, -0.9597],\n",
      "        [ 0.1830,  0.1784,  0.0000, -1.4945, -1.9444, -1.0193],\n",
      "        [ 0.3609,  0.6588,  1.5613,  0.0000, -1.3848, -0.4584],\n",
      "        [ 0.9275,  1.0909,  1.7933, -0.5525,  0.0000, -1.1931],\n",
      "        [ 0.5387,  0.9620,  0.5988, -0.6975, -0.5356,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "29\n",
      "tensor([ 0.5387,  0.7794,  0.8927, -1.2542, -0.1088, -1.4775])\n",
      "tensor([[ 0.0000,  0.4952,  1.0640, -0.9774, -3.3379, -1.6715],\n",
      "        [ 0.2484,  0.0000,  0.1477, -2.5687, -0.6713, -1.0104],\n",
      "        [ 0.1819,  0.1767,  0.0000, -1.5000, -1.9431, -1.0129],\n",
      "        [ 0.3668,  0.6642,  1.5650,  0.0000, -1.3703, -0.4439],\n",
      "        [ 0.9481,  1.1029,  1.7512, -0.5698,  0.0000, -1.1601],\n",
      "        [ 0.5391,  0.9453,  0.6225, -0.6816, -0.5367,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "30\n",
      "tensor([ 0.9473,  1.1200,  1.6803, -0.2013, -0.4539, -0.6550])\n",
      "tensor([[ 0.0000,  0.4794,  1.0874, -1.0103, -3.4078, -1.7490],\n",
      "        [ 0.2395,  0.0000,  0.1493, -2.6000, -0.6979, -1.0559],\n",
      "        [ 0.1816,  0.1750,  0.0000, -1.5078, -1.9344, -0.9994],\n",
      "        [ 0.3756,  0.6732,  1.5521,  0.0000, -1.3475, -0.4237],\n",
      "        [ 0.9577,  1.1047,  1.7193, -0.5866,  0.0000, -1.1418],\n",
      "        [ 0.5373,  0.9299,  0.6468, -0.6667, -0.5392,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "31\n",
      "tensor([ 0.8814,  0.5701,  0.0494, -0.2030, -0.0710, -0.7474])\n",
      "tensor([[ 0.0000,  0.4661,  1.1090, -1.0541, -3.4796, -1.8283],\n",
      "        [ 0.2307,  0.0000,  0.1517, -2.6300, -0.7291, -1.1053],\n",
      "        [ 0.1815,  0.1729,  0.0000, -1.5117, -1.9282, -0.9893],\n",
      "        [ 0.3890,  0.6826,  1.5290,  0.0000, -1.3137, -0.4000],\n",
      "        [ 0.9705,  1.0996,  1.6987, -0.5968,  0.0000, -1.1301],\n",
      "        [ 0.5320,  0.9153,  0.6726, -0.6546, -0.5440,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "32\n",
      "tensor([ 0.6065,  0.0350,  1.6391, -0.6020, -0.1336, -1.0102])\n",
      "tensor([[ 0.0000,  0.4548,  1.1284, -1.0984, -3.5505, -1.9078],\n",
      "        [ 0.2221,  0.0000,  0.1529, -2.6717, -0.7622, -1.1559],\n",
      "        [ 0.1801,  0.1703,  0.0000, -1.5226, -1.9295, -0.9864],\n",
      "        [ 0.4024,  0.6939,  1.5079,  0.0000, -1.2820, -0.3783],\n",
      "        [ 0.9862,  1.0807,  1.6827, -0.6111,  0.0000, -1.1236],\n",
      "        [ 0.5267,  0.8981,  0.7017, -0.6421, -0.5508,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "33\n",
      "tensor([ 0.9873,  1.1280,  0.4370, -1.2807, -1.3415, -0.4229])\n",
      "tensor([[ 0.0000,  0.4453,  1.1440, -1.1476, -3.6182, -1.9842],\n",
      "        [ 0.2149,  0.0000,  0.1558, -2.6966, -0.7973, -1.2084],\n",
      "        [ 0.1793,  0.1671,  0.0000, -1.5308, -1.9280, -0.9811],\n",
      "        [ 0.4184,  0.7042,  1.4766,  0.0000, -1.2449, -0.3559],\n",
      "        [ 0.9943,  1.0541,  1.6845, -0.6213,  0.0000, -1.1286],\n",
      "        [ 0.5268,  0.8867,  0.7195, -0.6318, -0.5527,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "34\n",
      "tensor([ 0.3341,  0.0735,  0.8008, -0.3021, -0.0311, -0.6090])\n",
      "tensor([[ 0.0000,  0.4376,  1.1564, -1.1953, -3.6818, -2.0568],\n",
      "        [ 0.2091,  0.0000,  0.1580, -2.7213, -0.8282, -1.2557],\n",
      "        [ 0.1781,  0.1637,  0.0000, -1.5439, -1.9275, -0.9781],\n",
      "        [ 0.4338,  0.7143,  1.4495,  0.0000, -1.2122, -0.3369],\n",
      "        [ 1.0001,  1.0279,  1.6825, -0.6351,  0.0000, -1.1362],\n",
      "        [ 0.5267,  0.8762,  0.7383, -0.6225, -0.5552,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "35\n",
      "tensor([ 0.9186,  1.7740,  0.9888, -0.9133, -1.8811, -0.9927])\n",
      "tensor([[ 0.0000,  0.4305,  1.1728, -1.2457, -3.7494, -2.1346],\n",
      "        [ 0.2045,  0.0000,  0.1597, -2.7436, -0.8523, -1.2953],\n",
      "        [ 0.1762,  0.1611,  0.0000, -1.5559, -1.9324, -0.9792],\n",
      "        [ 0.4504,  0.7248,  1.4211,  0.0000, -1.1802, -0.3190],\n",
      "        [ 1.0104,  1.0056,  1.6740, -0.6467,  0.0000, -1.1388],\n",
      "        [ 0.5291,  0.8646,  0.7517, -0.6150, -0.5557,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "36\n",
      "tensor([ 0.3932,  1.6860,  1.4849, -1.2743, -0.0566, -1.9860])\n",
      "tensor([[ 0.0000,  0.4228,  1.1968, -1.2974, -3.8186, -2.2169],\n",
      "        [ 0.2010,  0.0000,  0.1610, -2.7664, -0.8684, -1.3289],\n",
      "        [ 0.1746,  0.1604,  0.0000, -1.5657, -1.9374, -0.9797],\n",
      "        [ 0.4610,  0.7419,  1.4042,  0.0000, -1.1596, -0.3062],\n",
      "        [ 1.0186,  0.9982,  1.6666, -0.6551,  0.0000, -1.1414],\n",
      "        [ 0.5327,  0.8535,  0.7641, -0.6076, -0.5556,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "37\n",
      "tensor([ 1.0232,  0.7526,  1.0430, -2.3197, -1.0528, -0.7398])\n",
      "tensor([[ 0.0000,  0.4156,  1.2184, -1.3498, -3.8838, -2.2950],\n",
      "        [ 0.1974,  0.0000,  0.1629, -2.7893, -0.8888, -1.3657],\n",
      "        [ 0.1739,  0.1590,  0.0000, -1.5690, -1.9371, -0.9768],\n",
      "        [ 0.4732,  0.7619,  1.3794,  0.0000, -1.1340, -0.2925],\n",
      "        [ 1.0245,  0.9916,  1.6630, -0.6643,  0.0000, -1.1465],\n",
      "        [ 0.5362,  0.8465,  0.7795, -0.6015, -0.5562,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "38\n",
      "tensor([ 0.0019,  0.6379,  0.0992, -0.2336, -0.2653, -0.6063])\n",
      "tensor([[ 0.0000,  0.4097,  1.2396, -1.4054, -3.9505, -2.3730],\n",
      "        [ 0.1943,  0.0000,  0.1647, -2.8121, -0.9075, -1.4022],\n",
      "        [ 0.1733,  0.1581,  0.0000, -1.5658, -1.9380, -0.9734],\n",
      "        [ 0.4874,  0.7712,  1.3550,  0.0000, -1.1092, -0.2809],\n",
      "        [ 1.0229,  0.9877,  1.6653, -0.6749,  0.0000, -1.1567],\n",
      "        [ 0.5447,  0.8339,  0.7867, -0.5972, -0.5533,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "39\n",
      "tensor([ 0.5513,  0.1463,  0.3163, -0.9379, -1.3331, -0.0300])\n",
      "tensor([[ 0.0000,  0.4053,  1.2606, -1.4608, -4.0157, -2.4481],\n",
      "        [ 0.1920,  0.0000,  0.1669, -2.8328, -0.9215, -1.4360],\n",
      "        [ 0.1731,  0.1579,  0.0000, -1.5672, -1.9350, -0.9668],\n",
      "        [ 0.5023,  0.7778,  1.3366,  0.0000, -1.0850, -0.2702],\n",
      "        [ 1.0240,  0.9754,  1.6664, -0.6864,  0.0000, -1.1668],\n",
      "        [ 0.5545,  0.8242,  0.7882, -0.5929, -0.5496,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "40\n",
      "tensor([ 0.1880,  0.6408,  0.6850, -0.6557, -0.8466, -1.9335])\n",
      "tensor([[ 0.0000,  0.4010,  1.2800, -1.5223, -4.0787, -2.5226],\n",
      "        [ 0.1900,  0.0000,  0.1692, -2.8520, -0.9327, -1.4669],\n",
      "        [ 0.1721,  0.1578,  0.0000, -1.5683, -1.9353, -0.9640],\n",
      "        [ 0.5174,  0.7799,  1.3153,  0.0000, -1.0637, -0.2613],\n",
      "        [ 1.0282,  0.9667,  1.6666, -0.6977,  0.0000, -1.1776],\n",
      "        [ 0.5628,  0.8201,  0.7921, -0.5887, -0.5471,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "41\n",
      "tensor([ 1.5038,  1.9665,  0.3864, -0.4502, -1.0433, -0.9070])\n",
      "tensor([[ 0.0000,  0.3968,  1.2974, -1.5833, -4.1387, -2.5951],\n",
      "        [ 0.1884,  0.0000,  0.1723, -2.8649, -0.9416, -1.4934],\n",
      "        [ 0.1713,  0.1581,  0.0000, -1.5690, -1.9347, -0.9609],\n",
      "        [ 0.5342,  0.7822,  1.2874,  0.0000, -1.0404, -0.2522],\n",
      "        [ 1.0268,  0.9610,  1.6678, -0.7122,  0.0000, -1.1917],\n",
      "        [ 0.5698,  0.8179,  0.7980, -0.5838, -0.5454,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "42\n",
      "tensor([ 0.3206,  0.1467,  0.7422, -0.0106, -0.3675, -0.4823])\n",
      "tensor([[ 0.0000,  0.3927,  1.3136, -1.6427, -4.1946, -2.6631],\n",
      "        [ 0.1864,  0.0000,  0.1757, -2.8871, -0.9562, -1.5268],\n",
      "        [ 0.1707,  0.1577,  0.0000, -1.5700, -1.9332, -0.9577],\n",
      "        [ 0.5500,  0.7851,  1.2630,  0.0000, -1.0200, -0.2444],\n",
      "        [ 1.0240,  0.9545,  1.6786, -0.7287,  0.0000, -1.2102],\n",
      "        [ 0.5776,  0.8134,  0.8021, -0.5795, -0.5437,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "43\n",
      "tensor([ 0.9868,  1.2377,  0.8949, -0.4219, -1.1306, -0.6671])\n",
      "tensor([[ 0.0000,  0.3889,  1.3233, -1.7015, -4.2462, -2.7267],\n",
      "        [ 0.1844,  0.0000,  0.1788, -2.9078, -0.9697, -1.5583],\n",
      "        [ 0.1692,  0.1576,  0.0000, -1.5760, -1.9340, -0.9570],\n",
      "        [ 0.5646,  0.7895,  1.2439,  0.0000, -1.0049, -0.2384],\n",
      "        [ 1.0199,  0.9501,  1.6914, -0.7468,  0.0000, -1.2298],\n",
      "        [ 0.5853,  0.8080,  0.8079, -0.5765, -0.5426,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "44\n",
      "tensor([ 1.9652,  2.1552,  2.0926, -0.5482, -0.0645, -0.0199])\n",
      "tensor([[ 0.0000,  0.3857,  1.3319, -1.7592, -4.2944, -2.7869],\n",
      "        [ 0.1822,  0.0000,  0.1821, -2.9320, -0.9866, -1.5930],\n",
      "        [ 0.1673,  0.1580,  0.0000, -1.5841, -1.9369, -0.9581],\n",
      "        [ 0.5809,  0.7933,  1.2272,  0.0000, -0.9899, -0.2326],\n",
      "        [ 1.0200,  0.9470,  1.7004, -0.7635,  0.0000, -1.2481],\n",
      "        [ 0.5933,  0.7990,  0.8189, -0.5740, -0.5422,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "45\n",
      "tensor([ 1.3425,  0.4700,  1.1226, -0.5151, -0.2023, -0.3442])\n",
      "tensor([[ 0.0000,  0.3830,  1.3319, -1.8246, -4.3434, -2.8480],\n",
      "        [ 0.1792,  0.0000,  0.1838, -2.9657, -1.0100, -1.6354],\n",
      "        [ 0.1652,  0.1565,  0.0000, -1.5988, -1.9363, -0.9579],\n",
      "        [ 0.5965,  0.7982,  1.2310,  0.0000, -0.9831, -0.2294],\n",
      "        [ 1.0053,  0.9526,  1.7198, -0.7960,  0.0000, -1.2800],\n",
      "        [ 0.6102,  0.7814,  0.8228, -0.5685, -0.5379,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "46\n",
      "tensor([ 0.2428,  1.0756,  0.1073, -2.4169, -2.6986, -0.8562])\n",
      "tensor([[ 0.0000,  0.3799,  1.3292, -1.8866, -4.3882, -2.9044],\n",
      "        [ 0.1765,  0.0000,  0.1848, -2.9956, -1.0307, -1.6734],\n",
      "        [ 0.1631,  0.1551,  0.0000, -1.6138, -1.9367, -0.9584],\n",
      "        [ 0.6074,  0.8006,  1.2290,  0.0000, -0.9790, -0.2271],\n",
      "        [ 0.9954,  0.9585,  1.7377, -0.8270,  0.0000, -1.3090],\n",
      "        [ 0.6246,  0.7683,  0.8322, -0.5646, -0.5351,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "47\n",
      "tensor([ 0.9007,  0.0483,  0.0501, -0.2333, -0.0559, -0.0777])\n",
      "tensor([[ 0.0000,  0.3779,  1.3276, -1.9525, -4.4331, -2.9630],\n",
      "        [ 0.1749,  0.0000,  0.1863, -3.0143, -1.0413, -1.6979],\n",
      "        [ 0.1608,  0.1559,  0.0000, -1.6236, -1.9371, -0.9565],\n",
      "        [ 0.6142,  0.8049,  1.2268,  0.0000, -0.9773, -0.2258],\n",
      "        [ 0.9926,  0.9627,  1.7434, -0.8533,  0.0000, -1.3313],\n",
      "        [ 0.6382,  0.7613,  0.8371, -0.5616, -0.5331,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "48\n",
      "tensor([ 1.9583,  0.1154,  0.2594, -1.7090, -0.3089, -2.2513])\n",
      "tensor([[ 0.0000,  0.3764,  1.3247, -2.0121, -4.4741, -3.0163],\n",
      "        [ 0.1736,  0.0000,  0.1874, -3.0319, -1.0508, -1.7203],\n",
      "        [ 0.1583,  0.1576,  0.0000, -1.6346, -1.9407, -0.9580],\n",
      "        [ 0.6233,  0.8071,  1.2260,  0.0000, -0.9750, -0.2245],\n",
      "        [ 0.9896,  0.9660,  1.7488, -0.8807,  0.0000, -1.3538],\n",
      "        [ 0.6498,  0.7553,  0.8424, -0.5598, -0.5325,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "49\n",
      "tensor([ 1.6506,  0.4988,  0.4623, -1.3151, -0.6312, -0.1331])\n",
      "tensor([[ 0.0000,  0.3744,  1.3180, -2.0664, -4.5109, -3.0640],\n",
      "        [ 0.1720,  0.0000,  0.1896, -3.0565, -1.0652, -1.7495],\n",
      "        [ 0.1559,  0.1596,  0.0000, -1.6478, -1.9467, -0.9614],\n",
      "        [ 0.6333,  0.8124,  1.2241,  0.0000, -0.9725, -0.2232],\n",
      "        [ 0.9849,  0.9683,  1.7548, -0.9134,  0.0000, -1.3798],\n",
      "        [ 0.6658,  0.7537,  0.8487, -0.5577, -0.5313,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "50\n",
      "tensor([ 0.7478,  0.1076,  0.0911, -0.2089, -0.1436, -0.2526])\n",
      "tensor([[ 0.0000,  0.3737,  1.3124, -2.1199, -4.5465, -3.1104],\n",
      "        [ 0.1709,  0.0000,  0.1927, -3.0750, -1.0758, -1.7750],\n",
      "        [ 0.1538,  0.1616,  0.0000, -1.6585, -1.9514, -0.9634],\n",
      "        [ 0.6437,  0.8157,  1.2182,  0.0000, -0.9691, -0.2216],\n",
      "        [ 0.9822,  0.9627,  1.7599, -0.9442,  0.0000, -1.4052],\n",
      "        [ 0.6813,  0.7493,  0.8506, -0.5563, -0.5299,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "51\n",
      "tensor([ 1.7409,  0.5058,  1.1186, -0.9523, -1.4594, -0.8991])\n",
      "tensor([[ 0.0000,  0.3728,  1.3063, -2.1750, -4.5802, -3.1562],\n",
      "        [ 0.1698,  0.0000,  0.1989, -3.0965, -1.0877, -1.8065],\n",
      "        [ 0.1517,  0.1644,  0.0000, -1.6671, -1.9550, -0.9632],\n",
      "        [ 0.6535,  0.8186,  1.2046,  0.0000, -0.9653, -0.2194],\n",
      "        [ 0.9759,  0.9641,  1.7665, -0.9796,  0.0000, -1.4343],\n",
      "        [ 0.7002,  0.7439,  0.8524, -0.5534, -0.5280,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "52\n",
      "tensor([ 0.9931,  0.7505,  1.0158, -1.3335, -0.5565, -0.6560])\n",
      "tensor([[ 0.0000,  0.3722,  1.3001, -2.2308, -4.6131, -3.2021],\n",
      "        [ 0.1691,  0.0000,  0.2029, -3.1164, -1.0974, -1.8311],\n",
      "        [ 0.1500,  0.1658,  0.0000, -1.6770, -1.9584, -0.9624],\n",
      "        [ 0.6619,  0.8152,  1.1917,  0.0000, -0.9646, -0.2185],\n",
      "        [ 0.9700,  0.9657,  1.7715, -1.0181,  0.0000, -1.4643],\n",
      "        [ 0.7177,  0.7437,  0.8592, -0.5518, -0.5269,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "53\n",
      "tensor([ 0.3832,  0.2472,  2.0545, -0.6738, -0.4974, -0.0765])\n",
      "tensor([[ 0.0000,  0.3741,  1.2959, -2.2882, -4.6460, -3.2515],\n",
      "        [ 0.1694,  0.0000,  0.2064, -3.1313, -1.1018, -1.8435],\n",
      "        [ 0.1476,  0.1696,  0.0000, -1.6927, -1.9659, -0.9678],\n",
      "        [ 0.6741,  0.8061,  1.1778,  0.0000, -0.9620, -0.2167],\n",
      "        [ 0.9666,  0.9643,  1.7758, -1.0532,  0.0000, -1.4909],\n",
      "        [ 0.7312,  0.7482,  0.8636, -0.5512, -0.5266,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "54\n",
      "tensor([ 1.1992,  2.6308,  0.4674, -0.4113, -0.0940, -0.8819])\n",
      "tensor([[ 0.0000,  0.3778,  1.2983, -2.3522, -4.6793, -3.3070],\n",
      "        [ 0.1701,  0.0000,  0.2088, -3.1418, -1.1037, -1.8499],\n",
      "        [ 0.1461,  0.1722,  0.0000, -1.6967, -1.9683, -0.9614],\n",
      "        [ 0.6820,  0.8000,  1.1676,  0.0000, -0.9607, -0.2158],\n",
      "        [ 0.9710,  0.9484,  1.7776, -1.0801,  0.0000, -1.5093],\n",
      "        [ 0.7396,  0.7541,  0.8728, -0.5525, -0.5276,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "55\n",
      "tensor([ 0.8546,  0.6437,  0.3107, -0.4468, -0.3596, -0.9305])\n",
      "tensor([[ 0.0000,  0.3812,  1.3001, -2.4261, -4.7146, -3.3681],\n",
      "        [ 0.1717,  0.0000,  0.2076, -3.1356, -1.0961, -1.8339],\n",
      "        [ 0.1441,  0.1732,  0.0000, -1.7107, -1.9763, -0.9617],\n",
      "        [ 0.6847,  0.8009,  1.1616,  0.0000, -0.9627, -0.2164],\n",
      "        [ 0.9826,  0.9271,  1.7746, -1.1031,  0.0000, -1.5231],\n",
      "        [ 0.7413,  0.7726,  0.8886, -0.5557, -0.5297,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "56\n",
      "tensor([ 0.5209,  0.7620,  1.2764, -0.6646, -0.8287, -0.0312])\n",
      "tensor([[ 0.0000,  0.3838,  1.2997, -2.5081, -4.7516, -3.4323],\n",
      "        [ 0.1725,  0.0000,  0.2083, -3.1442, -1.0977, -1.8364],\n",
      "        [ 0.1408,  0.1750,  0.0000, -1.7462, -1.9975, -0.9817],\n",
      "        [ 0.6912,  0.8003,  1.1504,  0.0000, -0.9612, -0.2152],\n",
      "        [ 0.9981,  0.9111,  1.7785, -1.1276,  0.0000, -1.5408],\n",
      "        [ 0.7444,  0.7905,  0.9057, -0.5590, -0.5316,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "57\n",
      "tensor([ 0.7152,  2.4557,  0.6607, -1.8326, -1.3249, -0.3428])\n",
      "tensor([[ 0.0000,  0.3875,  1.2981, -2.5911, -4.7882, -3.4963],\n",
      "        [ 0.1734,  0.0000,  0.2076, -3.1528, -1.1000, -1.8379],\n",
      "        [ 0.1375,  0.1758,  0.0000, -1.7802, -2.0181, -1.0001],\n",
      "        [ 0.6942,  0.8055,  1.1448,  0.0000, -0.9614, -0.2150],\n",
      "        [ 1.0110,  0.8982,  1.7940, -1.1602,  0.0000, -1.5664],\n",
      "        [ 0.7534,  0.8011,  0.9234, -0.5608, -0.5322,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "58\n",
      "tensor([ 0.3086,  0.0474,  0.2169, -1.3059, -1.0979, -0.1044])\n",
      "tensor([[ 0.0000,  0.3929,  1.2947, -2.6873, -4.8309, -3.5684],\n",
      "        [ 0.1744,  0.0000,  0.2118, -3.1662, -1.1049, -1.8502],\n",
      "        [ 0.1342,  0.1782,  0.0000, -1.8138, -2.0400, -1.0196],\n",
      "        [ 0.7131,  0.7920,  1.1243,  0.0000, -0.9520, -0.2112],\n",
      "        [ 1.0199,  0.8903,  1.8137, -1.1947,  0.0000, -1.5927],\n",
      "        [ 0.7705,  0.8043,  0.9440, -0.5608, -0.5314,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "59\n",
      "tensor([ 0.0779,  0.8874,  0.9078, -1.1691, -0.2737, -3.0607])\n",
      "tensor([[ 0.0000,  0.3985,  1.2979, -2.7939, -4.8758, -3.6483],\n",
      "        [ 0.1764,  0.0000,  0.2146, -3.1656, -1.1020, -1.8466],\n",
      "        [ 0.1307,  0.1837,  0.0000, -1.8483, -2.0630, -1.0415],\n",
      "        [ 0.7333,  0.7746,  1.1042,  0.0000, -0.9409, -0.2070],\n",
      "        [ 1.0337,  0.8910,  1.8240, -1.2125,  0.0000, -1.6083],\n",
      "        [ 0.7855,  0.8060,  0.9690, -0.5622, -0.5315,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "60\n",
      "tensor([ 0.8549,  0.5687,  0.6793, -1.1173, -0.5372, -1.1159])\n",
      "tensor([[ 0.0000,  0.4039,  1.3027, -2.9014, -4.9197, -3.7280],\n",
      "        [ 0.1784,  0.0000,  0.2176, -3.1671, -1.0985, -1.8449],\n",
      "        [ 0.1275,  0.1899,  0.0000, -1.8816, -2.0830, -1.0641],\n",
      "        [ 0.7464,  0.7657,  1.0836,  0.0000, -0.9329, -0.2040],\n",
      "        [ 1.0585,  0.8843,  1.8239, -1.2075,  0.0000, -1.6072],\n",
      "        [ 0.7901,  0.8080,  0.9980, -0.5684, -0.5340,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "61\n",
      "tensor([ 2.5707,  0.6556,  1.2646, -0.2008, -0.0465, -0.5155])\n",
      "tensor([[ 0.0000,  0.4125,  1.3252, -3.0200, -4.9683, -3.8182],\n",
      "        [ 0.1814,  0.0000,  0.2147, -3.1536, -1.0874, -1.8267],\n",
      "        [ 0.1250,  0.1912,  0.0000, -1.9116, -2.1011, -1.0836],\n",
      "        [ 0.7486,  0.7754,  1.0821,  0.0000, -0.9283, -0.2031],\n",
      "        [ 1.0933,  0.8669,  1.8083, -1.1909,  0.0000, -1.5963],\n",
      "        [ 0.7957,  0.8131,  1.0305, -0.5733, -0.5353,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "62\n",
      "tensor([ 1.3519,  0.4824,  0.2019, -0.3032, -0.5958, -0.7000])\n",
      "tensor([[ 0.0000,  0.4192,  1.3341, -3.1282, -5.0135, -3.8994],\n",
      "        [ 0.1841,  0.0000,  0.2123, -3.1437, -1.0787, -1.8128],\n",
      "        [ 0.1225,  0.1939,  0.0000, -1.9403, -2.1208, -1.1025],\n",
      "        [ 0.7483,  0.7822,  1.0882,  0.0000, -0.9275, -0.2038],\n",
      "        [ 1.1225,  0.8564,  1.8015, -1.1879,  0.0000, -1.5953],\n",
      "        [ 0.8017,  0.8196,  1.0603, -0.5791, -0.5373,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "63\n",
      "tensor([ 2.4798,  3.0446,  0.6296, -1.0374, -0.3772, -0.8257])\n",
      "tensor([[ 0.0000,  0.4251,  1.3441, -3.2313, -5.0556, -3.9761],\n",
      "        [ 0.1863,  0.0000,  0.2103, -3.1362, -1.0719, -1.8016],\n",
      "        [ 0.1201,  0.1974,  0.0000, -1.9700, -2.1402, -1.1228],\n",
      "        [ 0.7476,  0.7961,  1.0929,  0.0000, -0.9263, -0.2039],\n",
      "        [ 1.1529,  0.8451,  1.7893, -1.1789,  0.0000, -1.5895],\n",
      "        [ 0.8094,  0.8266,  1.0843, -0.5837, -0.5387,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "64\n",
      "tensor([ 0.2844,  0.2919,  1.3843, -0.6195, -0.3217, -1.0152])\n",
      "tensor([[ 0.0000,  0.4291,  1.3516, -3.3341, -5.0969, -4.0516],\n",
      "        [ 0.1881,  0.0000,  0.2084, -3.1323, -1.0663, -1.7935],\n",
      "        [ 0.1180,  0.2003,  0.0000, -1.9958, -2.1567, -1.1402],\n",
      "        [ 0.7435,  0.8153,  1.1025,  0.0000, -0.9287, -0.2053],\n",
      "        [ 1.1841,  0.8371,  1.7700, -1.1663,  0.0000, -1.5805],\n",
      "        [ 0.8181,  0.8401,  1.1086, -0.5870, -0.5397,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "65\n",
      "tensor([ 1.7328,  0.2263,  0.3088, -1.1782, -0.5034, -1.0811])\n",
      "tensor([[ 0.0000,  0.4314,  1.3554, -3.4360, -5.1375, -4.1251],\n",
      "        [ 0.1902,  0.0000,  0.2053, -3.1217, -1.0560, -1.7785],\n",
      "        [ 0.1166,  0.2052,  0.0000, -2.0164, -2.1698, -1.1549],\n",
      "        [ 0.7393,  0.8368,  1.1109,  0.0000, -0.9301, -0.2062],\n",
      "        [ 1.2105,  0.8379,  1.7602, -1.1638,  0.0000, -1.5793],\n",
      "        [ 0.8260,  0.8563,  1.1319, -0.5890, -0.5403,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "66\n",
      "tensor([ 1.7333,  0.6354,  0.5134, -0.7886, -0.1475, -0.2049])\n",
      "tensor([[ 0.0000,  0.4356,  1.3603, -3.5357, -5.1797, -4.1983],\n",
      "        [ 0.1935,  0.0000,  0.1997, -3.1114, -1.0406, -1.7609],\n",
      "        [ 0.1158,  0.2058,  0.0000, -2.0323, -2.1774, -1.1642],\n",
      "        [ 0.7341,  0.8644,  1.1257,  0.0000, -0.9310, -0.2065],\n",
      "        [ 1.2449,  0.8203,  1.7364, -1.1690,  0.0000, -1.5796],\n",
      "        [ 0.8339,  0.8778,  1.1692, -0.5901, -0.5408,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "67\n",
      "tensor([ 0.0900,  0.6998,  1.5360, -0.1028, -1.5710, -2.2348])\n",
      "tensor([[ 0.0000,  0.4401,  1.3608, -3.6280, -5.2195, -4.2660],\n",
      "        [ 0.1972,  0.0000,  0.1943, -3.1027, -1.0220, -1.7427],\n",
      "        [ 0.1146,  0.2076,  0.0000, -2.0563, -2.1929, -1.1816],\n",
      "        [ 0.7297,  0.8890,  1.1403,  0.0000, -0.9329, -0.2071],\n",
      "        [ 1.2797,  0.8023,  1.7300, -1.1772,  0.0000, -1.5823],\n",
      "        [ 0.8455,  0.8922,  1.1951, -0.5906, -0.5404,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "68\n",
      "tensor([ 0.3554,  0.5443,  1.1681, -0.4033, -0.3700, -1.8217])\n",
      "tensor([[ 0.0000,  0.4451,  1.3640, -3.7142, -5.2568, -4.3294],\n",
      "        [ 0.2011,  0.0000,  0.1895, -3.0890, -1.0027, -1.7212],\n",
      "        [ 0.1136,  0.2094,  0.0000, -2.0763, -2.2045, -1.1947],\n",
      "        [ 0.7257,  0.9053,  1.1507,  0.0000, -0.9344, -0.2077],\n",
      "        [ 1.3088,  0.7855,  1.7241, -1.1864,  0.0000, -1.5861],\n",
      "        [ 0.8516,  0.9073,  1.2266, -0.5925, -0.5420,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "69\n",
      "tensor([ 0.1181,  1.0406,  1.2618, -1.7873, -1.7839, -0.5867])\n",
      "tensor([[ 0.0000,  0.4493,  1.3654, -3.8018, -5.2935, -4.3927],\n",
      "        [ 0.2047,  0.0000,  0.1852, -3.0769, -0.9843, -1.7015],\n",
      "        [ 0.1122,  0.2103,  0.0000, -2.1051, -2.2209, -1.2159],\n",
      "        [ 0.7225,  0.9245,  1.1625,  0.0000, -0.9371, -0.2086],\n",
      "        [ 1.3369,  0.7733,  1.7223, -1.1879,  0.0000, -1.5859],\n",
      "        [ 0.8550,  0.9249,  1.2684, -0.5970, -0.5455,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "70\n",
      "tensor([ 0.0678,  0.4119,  0.6075, -2.0584, -1.4962, -0.4988])\n",
      "tensor([[ 0.0000,  0.4539,  1.3764, -3.8985, -5.3330, -4.4629],\n",
      "        [ 0.2082,  0.0000,  0.1768, -3.0676, -0.9661, -1.6824],\n",
      "        [ 0.1112,  0.2096,  0.0000, -2.1189, -2.2309, -1.2250],\n",
      "        [ 0.7226,  0.9294,  1.1610,  0.0000, -0.9385, -0.2104],\n",
      "        [ 1.3571,  0.7701,  1.7320, -1.1888,  0.0000, -1.5882],\n",
      "        [ 0.8642,  0.9353,  1.3015, -0.6001, -0.5484,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "71\n",
      "tensor([ 0.8330,  0.0596,  0.3012, -0.4425, -0.9175, -0.6040])\n",
      "tensor([[ 0.0000,  0.4594,  1.3842, -3.9860, -5.3684, -4.5258],\n",
      "        [ 0.2119,  0.0000,  0.1691, -3.0611, -0.9511, -1.6668],\n",
      "        [ 0.1103,  0.2092,  0.0000, -2.1327, -2.2398, -1.2343],\n",
      "        [ 0.7251,  0.9310,  1.1637,  0.0000, -0.9401, -0.2121],\n",
      "        [ 1.3768,  0.7638,  1.7367, -1.1878,  0.0000, -1.5897],\n",
      "        [ 0.8691,  0.9497,  1.3414, -0.6036, -0.5527,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "72\n",
      "tensor([ 0.5889,  1.9023,  1.1182, -0.5455, -0.0089, -1.8976])\n",
      "tensor([[ 0.0000,  0.4661,  1.4062, -4.0618, -5.4096, -4.5871],\n",
      "        [ 0.2150,  0.0000,  0.1611, -3.0607, -0.9387, -1.6568],\n",
      "        [ 0.1101,  0.2041,  0.0000, -2.1520, -2.2349, -1.2398],\n",
      "        [ 0.7278,  0.9372,  1.1788,  0.0000, -0.9447, -0.2143],\n",
      "        [ 1.3886,  0.7584,  1.7456, -1.1936,  0.0000, -1.5984],\n",
      "        [ 0.8804,  0.9521,  1.3528, -0.6098, -0.5549,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "73\n",
      "tensor([ 0.8264,  0.2992,  1.1236, -0.4019, -0.9978, -1.2595])\n",
      "tensor([[ 0.0000,  0.4724,  1.4346, -4.1495, -5.4551, -4.6582],\n",
      "        [ 0.2186,  0.0000,  0.1520, -3.0612, -0.9197, -1.6420],\n",
      "        [ 0.1094,  0.2006,  0.0000, -2.1804, -2.2408, -1.2575],\n",
      "        [ 0.7316,  0.9423,  1.1920,  0.0000, -0.9486, -0.2164],\n",
      "        [ 1.4034,  0.7588,  1.7558, -1.1836,  0.0000, -1.5982],\n",
      "        [ 0.8857,  0.9647,  1.3777, -0.6163, -0.5595,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "74\n",
      "tensor([ 1.0339,  1.3230,  0.8333, -0.7245, -1.3288, -0.5271])\n",
      "tensor([[ 0.0000,  0.4797,  1.4591, -4.2323, -5.4981, -4.7248],\n",
      "        [ 0.2226,  0.0000,  0.1437, -3.0589, -0.8986, -1.6245],\n",
      "        [ 0.1089,  0.1969,  0.0000, -2.2002, -2.2441, -1.2692],\n",
      "        [ 0.7325,  0.9488,  1.2040,  0.0000, -0.9552, -0.2193],\n",
      "        [ 1.4104,  0.7660,  1.7739, -1.1750,  0.0000, -1.6024],\n",
      "        [ 0.8937,  0.9687,  1.3929, -0.6216, -0.5632,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "75\n",
      "tensor([ 0.3538,  0.8826,  1.6303, -0.5141, -1.2291, -1.2165])\n",
      "tensor([[ 0.0000,  0.4890,  1.4848, -4.3088, -5.5436, -4.7906],\n",
      "        [ 0.2282,  0.0000,  0.1355, -3.0593, -0.8663, -1.6004],\n",
      "        [ 0.1081,  0.1957,  0.0000, -2.2164, -2.2513, -1.2809],\n",
      "        [ 0.7436,  0.9332,  1.2037,  0.0000, -0.9514, -0.2212],\n",
      "        [ 1.4046,  0.7848,  1.8021, -1.1643,  0.0000, -1.6130],\n",
      "        [ 0.8996,  0.9808,  1.4144, -0.6244, -0.5687,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "76\n",
      "tensor([ 0.7676,  1.5264,  0.2457, -0.0518, -1.1629, -0.5595])\n",
      "tensor([[ 0.0000,  0.4983,  1.5129, -4.3823, -5.5895, -4.8550],\n",
      "        [ 0.2338,  0.0000,  0.1277, -3.0620, -0.8347, -1.5782],\n",
      "        [ 0.1076,  0.1932,  0.0000, -2.2278, -2.2535, -1.2870],\n",
      "        [ 0.7570,  0.9228,  1.2030,  0.0000, -0.9469, -0.2215],\n",
      "        [ 1.4050,  0.7937,  1.8135, -1.1595,  0.0000, -1.6221],\n",
      "        [ 0.8978,  0.9847,  1.4438, -0.6313, -0.5769,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "77\n",
      "tensor([ 0.4406,  0.2287,  0.6555, -0.9516, -1.8213, -2.7535])\n",
      "tensor([[ 0.0000,  0.5076,  1.5397, -4.4591, -5.6397, -4.9226],\n",
      "        [ 0.2398,  0.0000,  0.1193, -3.0631, -0.7999, -1.5530],\n",
      "        [ 0.1068,  0.1896,  0.0000, -2.2495, -2.2617, -1.3023],\n",
      "        [ 0.7715,  0.9201,  1.2127,  0.0000, -0.9450, -0.2222],\n",
      "        [ 1.4040,  0.8019,  1.8290, -1.1702,  0.0000, -1.6432],\n",
      "        [ 0.9036,  0.9802,  1.4664, -0.6394, -0.5819,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "78\n",
      "tensor([ 0.6687,  0.3942,  0.8166, -1.3114, -0.1198, -0.5725])\n",
      "tensor([[ 0.0000,  0.5151,  1.5614, -4.5318, -5.6855, -4.9851],\n",
      "        [ 0.2442,  0.0000,  0.1134, -3.0827, -0.7700, -1.5432],\n",
      "        [ 0.1059,  0.1899,  0.0000, -2.2608, -2.2756, -1.3135],\n",
      "        [ 0.7874,  0.9093,  1.2210,  0.0000, -0.9412, -0.2233],\n",
      "        [ 1.3967,  0.8134,  1.8384, -1.1871,  0.0000, -1.6715],\n",
      "        [ 0.9069,  0.9551,  1.5133, -0.6544, -0.5872,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "79\n",
      "tensor([ 1.6777,  1.1628,  1.6046, -0.0238, -0.3727, -0.4429])\n",
      "tensor([[ 0.0000,  0.5221,  1.5721, -4.5996, -5.7283, -5.0425],\n",
      "        [ 0.2481,  0.0000,  0.1086, -3.1067, -0.7449, -1.5396],\n",
      "        [ 0.1051,  0.1905,  0.0000, -2.2679, -2.2869, -1.3212],\n",
      "        [ 0.8048,  0.8898,  1.2339,  0.0000, -0.9368, -0.2253],\n",
      "        [ 1.3916,  0.8208,  1.8531, -1.2042,  0.0000, -1.6991],\n",
      "        [ 0.9096,  0.9353,  1.5565, -0.6704, -0.5937,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "80\n",
      "tensor([ 1.5611,  0.5305,  1.3587, -0.7775, -0.0351, -0.4803])\n",
      "tensor([[ 0.0000,  0.5285,  1.5787, -4.6670, -5.7699, -5.0992],\n",
      "        [ 0.2512,  0.0000,  0.1045, -3.1328, -0.7239, -1.5398],\n",
      "        [ 0.1041,  0.1904,  0.0000, -2.2792, -2.3003, -1.3326],\n",
      "        [ 0.8240,  0.8687,  1.2499,  0.0000, -0.9325, -0.2274],\n",
      "        [ 1.3833,  0.8277,  1.8731, -1.2275,  0.0000, -1.7315],\n",
      "        [ 0.9125,  0.9255,  1.5984, -0.6832, -0.5999,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "81\n",
      "tensor([ 0.3827,  0.5624,  1.1162, -0.5601, -0.3016, -0.0479])\n",
      "tensor([[ 0.0000,  0.5351,  1.5823, -4.7344, -5.8107, -5.1546],\n",
      "        [ 0.2548,  0.0000,  0.1006, -3.1548, -0.7028, -1.5384],\n",
      "        [ 0.1036,  0.1886,  0.0000, -2.2855, -2.3030, -1.3382],\n",
      "        [ 0.8395,  0.8524,  1.2765,  0.0000, -0.9311, -0.2301],\n",
      "        [ 1.3749,  0.8400,  1.8878, -1.2416,  0.0000, -1.7579],\n",
      "        [ 0.9135,  0.9085,  1.6532, -0.7009, -0.6086,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "82\n",
      "tensor([ 1.1051,  0.9088,  1.3746, -1.0303, -1.6450, -0.6694])\n",
      "tensor([[ 0.0000,  0.5410,  1.5913, -4.8010, -5.8521, -5.2085],\n",
      "        [ 0.2579,  0.0000,  0.0971, -3.1793, -0.6858, -1.5414],\n",
      "        [ 0.1033,  0.1864,  0.0000, -2.2875, -2.3003, -1.3401],\n",
      "        [ 0.8538,  0.8383,  1.2964,  0.0000, -0.9310, -0.2335],\n",
      "        [ 1.3615,  0.8493,  1.9093, -1.2648,  0.0000, -1.7901],\n",
      "        [ 0.9206,  0.8862,  1.6913, -0.7186, -0.6147,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "83\n",
      "tensor([ 1.6099,  0.6117,  0.1502, -0.2893, -0.7031, -0.2757])\n",
      "tensor([[ 0.0000,  0.5471,  1.5994, -4.8656, -5.8915, -5.2600],\n",
      "        [ 0.2605,  0.0000,  0.0945, -3.2056, -0.6726, -1.5476],\n",
      "        [ 0.1031,  0.1838,  0.0000, -2.2880, -2.2983, -1.3414],\n",
      "        [ 0.8730,  0.8272,  1.2982,  0.0000, -0.9263, -0.2354],\n",
      "        [ 1.3385,  0.8619,  1.9476, -1.3020,  0.0000, -1.8316],\n",
      "        [ 0.9325,  0.8614,  1.7176, -0.7337, -0.6194,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "84\n",
      "tensor([ 0.9171,  0.4023,  0.0653, -1.8920, -0.5333, -1.1295])\n",
      "tensor([[ 0.0000,  0.5521,  1.6108, -4.9313, -5.9292, -5.3115],\n",
      "        [ 0.2624,  0.0000,  0.0926, -3.2403, -0.6617, -1.5604],\n",
      "        [ 0.1032,  0.1816,  0.0000, -2.2788, -2.2919, -1.3344],\n",
      "        [ 0.8953,  0.8115,  1.2940,  0.0000, -0.9206, -0.2371],\n",
      "        [ 1.3110,  0.8756,  1.9944, -1.3428,  0.0000, -1.8725],\n",
      "        [ 0.9466,  0.8397,  1.7305, -0.7456, -0.6231,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "85\n",
      "tensor([ 2.0976,  1.4464,  0.6493, -0.3197, -0.4748, -0.7524])\n",
      "tensor([[ 0.0000,  0.5557,  1.6182, -4.9928, -5.9642, -5.3597],\n",
      "        [ 0.2643,  0.0000,  0.0906, -3.2676, -0.6507, -1.5688],\n",
      "        [ 0.1033,  0.1796,  0.0000, -2.2655, -2.2838, -1.3237],\n",
      "        [ 0.9121,  0.7950,  1.2912,  0.0000, -0.9185, -0.2402],\n",
      "        [ 1.2863,  0.8831,  2.0433, -1.3913,  0.0000, -1.9178],\n",
      "        [ 0.9578,  0.8269,  1.7496, -0.7573, -0.6274,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "86\n",
      "tensor([ 1.6127,  0.1447,  0.1275, -0.6495, -0.3256, -0.3419])\n",
      "tensor([[ 0.0000,  0.5592,  1.6309, -5.0530, -5.9975, -5.4057],\n",
      "        [ 0.2662,  0.0000,  0.0888, -3.2882, -0.6398, -1.5725],\n",
      "        [ 0.1034,  0.1772,  0.0000, -2.2556, -2.2772, -1.3167],\n",
      "        [ 0.9301,  0.7828,  1.2857,  0.0000, -0.9173, -0.2438],\n",
      "        [ 1.2732,  0.8893,  2.0774, -1.4274,  0.0000, -1.9529],\n",
      "        [ 0.9692,  0.8148,  1.7596, -0.7678, -0.6315,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "87\n",
      "tensor([ 1.2776,  1.2590,  0.4090, -1.2740, -0.4405, -1.0224])\n",
      "tensor([[ 0.0000,  0.5651,  1.6440, -5.1093, -6.0289, -5.4481],\n",
      "        [ 0.2694,  0.0000,  0.0869, -3.3048, -0.6293, -1.5746],\n",
      "        [ 0.1038,  0.1731,  0.0000, -2.2404, -2.2684, -1.3059],\n",
      "        [ 0.9475,  0.7718,  1.2785,  0.0000, -0.9157, -0.2467],\n",
      "        [ 1.2614,  0.8972,  2.1166, -1.4665,  0.0000, -1.9882],\n",
      "        [ 0.9869,  0.7946,  1.7547, -0.7776, -0.6349,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "88\n",
      "tensor([ 0.2694,  0.5436,  1.0189, -0.3577, -0.8294, -0.1433])\n",
      "tensor([[ 0.0000,  0.5694,  1.6531, -5.1601, -6.0583, -5.4863],\n",
      "        [ 0.2722,  0.0000,  0.0853, -3.3185, -0.6194, -1.5740],\n",
      "        [ 0.1044,  0.1708,  0.0000, -2.2320, -2.2635, -1.3031],\n",
      "        [ 0.9636,  0.7668,  1.2680,  0.0000, -0.9173, -0.2513],\n",
      "        [ 1.2431,  0.8987,  2.1759, -1.5173,  0.0000, -2.0284],\n",
      "        [ 1.0084,  0.7805,  1.7345, -0.7886, -0.6389,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "89\n",
      "tensor([ 1.1883,  3.0902,  1.5081, -0.3501, -1.1013, -0.4688])\n",
      "tensor([[ 0.0000,  0.5721,  1.6569, -5.2029, -6.0845, -5.5188],\n",
      "        [ 0.2747,  0.0000,  0.0838, -3.3302, -0.6106, -1.5726],\n",
      "        [ 0.1050,  0.1685,  0.0000, -2.2175, -2.2617, -1.3008],\n",
      "        [ 0.9757,  0.7640,  1.2557,  0.0000, -0.9204, -0.2566],\n",
      "        [ 1.2238,  0.9044,  2.2378, -1.5734,  0.0000, -2.0698],\n",
      "        [ 1.0302,  0.7710,  1.7046, -0.7966, -0.6429,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "90\n",
      "tensor([ 1.0605,  0.4962,  1.2613, -0.2534, -1.5506, -1.1368])\n",
      "tensor([[ 0.0000,  0.5732,  1.6571, -5.2445, -6.1096, -5.5500],\n",
      "        [ 0.2770,  0.0000,  0.0837, -3.3596, -0.6002, -1.5770],\n",
      "        [ 0.1055,  0.1668,  0.0000, -2.1861, -2.2567, -1.2862],\n",
      "        [ 0.9850,  0.7727,  1.2325,  0.0000, -0.9261, -0.2618],\n",
      "        [ 1.2030,  0.9164,  2.2872, -1.6350,  0.0000, -2.1174],\n",
      "        [ 1.0494,  0.7716,  1.6734, -0.8019, -0.6482,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "91\n",
      "tensor([ 1.1267,  0.4714,  1.6111, -0.2324, -0.1224, -0.7822])\n",
      "tensor([[ 0.0000,  0.5745,  1.6540, -5.2826, -6.1332, -5.5789],\n",
      "        [ 0.2799,  0.0000,  0.0837, -3.3840, -0.5897, -1.5786],\n",
      "        [ 0.1060,  0.1655,  0.0000, -2.1563, -2.2510, -1.2716],\n",
      "        [ 0.9907,  0.7789,  1.2126,  0.0000, -0.9324, -0.2675],\n",
      "        [ 1.1866,  0.9252,  2.3302, -1.6907,  0.0000, -2.1588],\n",
      "        [ 1.0663,  0.7719,  1.6444, -0.8075, -0.6541,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "92\n",
      "tensor([ 0.8553,  0.0663,  1.7492, -2.8822, -0.6046, -1.7016])\n",
      "tensor([[ 0.0000,  0.5796,  1.6536, -5.3299, -6.1572, -5.6136],\n",
      "        [ 0.2863,  0.0000,  0.0828, -3.3852, -0.5824, -1.5654],\n",
      "        [ 0.1061,  0.1642,  0.0000, -2.1357, -2.2493, -1.2640],\n",
      "        [ 0.9961,  0.7838,  1.1977,  0.0000, -0.9388, -0.2738],\n",
      "        [ 1.1811,  0.9201,  2.3579, -1.7272,  0.0000, -2.1861],\n",
      "        [ 1.0710,  0.7842,  1.6435, -0.8234, -0.6612,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "93\n",
      "tensor([ 0.0078,  2.7913,  0.6422, -0.7812, -1.5743, -0.9371])\n",
      "tensor([[ 0.0000,  0.5859,  1.6549, -5.3833, -6.1791, -5.6506],\n",
      "        [ 0.2918,  0.0000,  0.0819, -3.3892, -0.5782, -1.5581],\n",
      "        [ 0.1062,  0.1625,  0.0000, -2.1103, -2.2508, -1.2536],\n",
      "        [ 0.9917,  0.7925,  1.1926,  0.0000, -0.9458, -0.2839],\n",
      "        [ 1.1871,  0.9028,  2.3689, -1.7321,  0.0000, -2.1965],\n",
      "        [ 1.0679,  0.7991,  1.6517, -0.8453, -0.6678,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "94\n",
      "tensor([ 1.2608,  0.5673,  1.0412, -1.5541, -0.3475, -0.2869])\n",
      "tensor([[ 0.0000,  0.5968,  1.6736, -5.4587, -6.1979, -5.6981],\n",
      "        [ 0.3004,  0.0000,  0.0803, -3.3619, -0.5785, -1.5348],\n",
      "        [ 0.1068,  0.1595,  0.0000, -2.0745, -2.2494, -1.2343],\n",
      "        [ 0.9695,  0.8152,  1.2000,  0.0000, -0.9516, -0.2981],\n",
      "        [ 1.2115,  0.8723,  2.3456, -1.6955,  0.0000, -2.1814],\n",
      "        [ 1.0457,  0.8250,  1.6900, -0.8824, -0.6732,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "95\n",
      "tensor([ 0.6121,  0.0245,  0.6396, -0.4120, -0.6136, -1.9503])\n",
      "tensor([[ 0.0000,  0.6044,  1.6974, -5.5445, -6.2229, -5.7562],\n",
      "        [ 0.3054,  0.0000,  0.0798, -3.3629, -0.5835, -1.5354],\n",
      "        [ 0.1075,  0.1587,  0.0000, -2.0264, -2.2512, -1.2098],\n",
      "        [ 0.9512,  0.8377,  1.2167,  0.0000, -0.9566, -0.3135],\n",
      "        [ 1.2401,  0.8473,  2.3267, -1.6588,  0.0000, -2.1605],\n",
      "        [ 1.0270,  0.8511,  1.7228, -0.9175, -0.6782,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "96\n",
      "tensor([ 1.7411,  0.4641,  0.8757, -1.9471, -0.3105, -1.3873])\n",
      "tensor([[ 0.0000,  0.6128,  1.7295, -5.6364, -6.2496, -5.8190],\n",
      "        [ 0.3092,  0.0000,  0.0795, -3.3706, -0.5883, -1.5390],\n",
      "        [ 0.1083,  0.1564,  0.0000, -1.9811, -2.2542, -1.1881],\n",
      "        [ 0.9380,  0.8567,  1.2264,  0.0000, -0.9639, -0.3297],\n",
      "        [ 1.2717,  0.8218,  2.3115, -1.6202,  0.0000, -2.1318],\n",
      "        [ 1.0144,  0.8700,  1.7452, -0.9517, -0.6823,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "97\n",
      "tensor([ 2.1152,  0.3986,  0.9668, -1.6368, -1.9481, -1.1752])\n",
      "tensor([[ 0.0000,  0.6188,  1.7543, -5.7233, -6.2764, -5.8795],\n",
      "        [ 0.3130,  0.0000,  0.0791, -3.3714, -0.5918, -1.5371],\n",
      "        [ 0.1088,  0.1553,  0.0000, -1.9409, -2.2563, -1.1686],\n",
      "        [ 0.9227,  0.8805,  1.2418,  0.0000, -0.9734, -0.3489],\n",
      "        [ 1.3006,  0.8010,  2.3009, -1.5893,  0.0000, -2.1082],\n",
      "        [ 1.0025,  0.8897,  1.7678, -0.9889, -0.6878,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "98\n",
      "tensor([ 0.5226,  1.8901,  0.5098, -0.1626, -0.2334, -0.6631])\n",
      "tensor([[ 0.0000,  0.6265,  1.7757, -5.8048, -6.3033, -5.9366],\n",
      "        [ 0.3176,  0.0000,  0.0784, -3.3728, -0.5953, -1.5371],\n",
      "        [ 0.1089,  0.1539,  0.0000, -1.9142, -2.2647, -1.1593],\n",
      "        [ 0.9076,  0.9089,  1.2635,  0.0000, -0.9844, -0.3685],\n",
      "        [ 1.3269,  0.7782,  2.2915, -1.5785,  0.0000, -2.1029],\n",
      "        [ 0.9976,  0.9032,  1.7869, -1.0220, -0.6921,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[50.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 10.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.]])\n",
      "99\n",
      "tensor([ 0.9699,  1.0066,  0.3423, -1.2533, -0.1130, -0.9418])\n",
      "tensor([[ 0.0000,  0.6329,  1.7936, -5.8773, -6.3284, -5.9878],\n",
      "        [ 0.3212,  0.0000,  0.0778, -3.3763, -0.5987, -1.5389],\n",
      "        [ 0.1086,  0.1525,  0.0000, -1.8963, -2.2762, -1.1561],\n",
      "        [ 0.8991,  0.9332,  1.2791,  0.0000, -0.9927, -0.3869],\n",
      "        [ 1.3427,  0.7616,  2.2923, -1.5791,  0.0000, -2.1074],\n",
      "        [ 0.9963,  0.9130,  1.8017, -1.0560, -0.6961,  0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#this is to learn and simulate \n",
    "#E and I nerons do not mix randomly \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "n=6\n",
    "tao=100\n",
    "dt = 1e-2\n",
    "T=int(10/dt)\n",
    "B=10\n",
    "w=torch.randn(n,n, device='cpu', requires_grad=True,dtype=torch.float)\n",
    "lr = 1e-1\n",
    "n_epochs = 100\n",
    "\n",
    "optimizer = optim.Adam([w], lr=lr)\n",
    "V=torch.zeros(T,n)\n",
    "ep=np.arange(n_epochs)\n",
    "Loss=torch.zeros(n_epochs,)\n",
    "\n",
    "# P1=(np.absolute(np.random.randint(low=2, high=100, size=math.ceil(n/2))))\n",
    "# p_ones=torch.ones(int(math.ceil(n/2)),dtype=torch.float)\n",
    "# p2=torch.from_numpy(np.append(P1,p_ones))\n",
    "\n",
    "print (w)\n",
    "for epoch in range(n_epochs):\n",
    "    P1=np.array([50,20,10])\n",
    "    p2=torch.from_numpy(np.append(P1,[1,1,1]))\n",
    "    p3=torch.diag(p2)\n",
    "    p1=p3.type(dtype=torch.float)\n",
    "    print (p1)\n",
    "    print (epoch)\n",
    "    \n",
    "    ze =  torch.from_numpy(np.absolute(np.array(np.random.normal(0, 1, math.ceil(n/2)))))\n",
    "     \n",
    "    zi =  torch.from_numpy(-np.absolute(np.array(np.random.normal(0, 1, round(n/2)) )))\n",
    "  \n",
    "    z1 = torch.cat((ze,zi),0)\n",
    "\n",
    "    z=z1.type(dtype=torch.float)\n",
    "    print (z)\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "    #generate weight matrix \n",
    "    Tr1=torch.ones(int(math.ceil(n/2)),dtype=torch.float)\n",
    "    Tr2=torch.ones(int(round(n/2)),dtype=torch.float)\n",
    "    Tr=torch.cat((Tr1,-Tr2),0)\n",
    "\n",
    "    #transform=torch.tensor([1,1,1,-1,-1,-1],dtype=torch.float)\n",
    "    Transform=torch.diag(Tr)\n",
    "    w_softplus=F.softplus(w)\n",
    "    wi=w_softplus@Transform\n",
    "    w1=torch.diag(wi)\n",
    "    w_rec=torch.diag(w1)\n",
    "    w1_rec = wi-w_rec\n",
    "    print (w1_rec)\n",
    "\n",
    "\n",
    "    \n",
    "    loss=0\n",
    "    for t in range(T):\n",
    "        N=torch.randn(1,n)\n",
    "        z_dot=(-z+(z@w1_rec)/math.sqrt(n))\n",
    "        z = z + z_dot*dt+N*math.sqrt(dt)\n",
    "        loss = loss + ((z@p1)**2).mean()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    Loss[epoch]=loss\n",
    "   \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#this is to plot the graph \n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:mint green')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.title('Learning curve')\n",
    "df=pd.DataFrame(Loss.detach().numpy())\n",
    "rolling_mean = df.rolling(window=10).mean()\n",
    "plt.plot(ep, rolling_mean, label='Learning Curve', color='k')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:mint green')\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('Penalty')\n",
    "plt.title('Variance vs Penalty')\n",
    "plt.grid(True)\n",
    "color=['b','c','k','g','w','m','r','y']\n",
    "for a in range(8):\n",
    "    \n",
    "    ze =  torch.from_numpy(np.absolute(np.array(np.random.normal(0, 1, math.ceil(n/2)))))\n",
    "    \n",
    "    zi =  torch.from_numpy(-np.absolute(np.array(np.random.normal(0, 1, round(n/2)))))\n",
    " \n",
    "    z1 = torch.cat((ze,zi),0)\n",
    "  \n",
    "    z=z1.type(dtype=torch.float)\n",
    "    Z=torch.zeros(T,n)\n",
    "    for t in range(T):\n",
    "        N=torch.randn(1,n)\n",
    "        z_dot=(-z+(z@w1_rec)/math.sqrt(n))\n",
    "        z = z + z_dot*dt+N*math.sqrt(dt)\n",
    "        Z[t] = z\n",
    "        Z_split = torch.split(Z,int(T/2),dim=0)[1]\n",
    "        \n",
    "    V=torch.zeros(n,1)\n",
    "    \n",
    "\n",
    "    for i in range(n):\n",
    "        V[i]=torch.var(Z_split[:,i])  \n",
    "        \n",
    "    plt.scatter(p2,V.detach().numpy(),color=color[a])   \n",
    "    plt.plot(p2.detach().numpy(),V.detach().numpy(),color=color[a]) \n",
    "    \n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (p2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
